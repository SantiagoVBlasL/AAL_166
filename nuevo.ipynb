{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2719512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: no es un repositorio git (ni ninguno de los directorios superiores): .git\n",
      "2025-06-04 17:36:53,573 - WARNING - nuevo.py:1017 - No se pudo obtener el git hash: Command '['git', 'rev-parse', 'HEAD']' returned non-zero exit status 128.\n",
      "2025-06-04 17:36:53,573 - INFO - nuevo.py:1021 - --- Configuración de la Ejecución ---\n",
      "2025-06-04 17:36:53,573 - INFO - nuevo.py:1023 - batch_size: 32\n",
      "2025-06-04 17:36:53,573 - INFO - nuevo.py:1023 - beta_vae: 1.0\n",
      "2025-06-04 17:36:53,573 - INFO - nuevo.py:1023 - channels_to_use: ['1', '2', '3']\n",
      "2025-06-04 17:36:53,573 - INFO - nuevo.py:1023 - classifier_stratify_cols: ['Sex', 'Site']\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - classifier_type: svm\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - classifier_use_class_weight: True\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - cyclical_beta_n_cycles: 4\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - cyclical_beta_ratio_increase: 0.5\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - dropout_rate_vae: 0.2\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - early_stopping_patience_vae: 25\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - epochs_vae: 450\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - git_hash: N/A\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - global_tensor_path: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - gridsearch_scoring: balanced_accuracy\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - inner_folds: 3\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - intermediate_fc_dim_vae: half\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - latent_dim: 512\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - log_interval_epochs_vae: 10\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - lr_scheduler_patience_vae: 15\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - lr_vae: 0.0001\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - metadata_path: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - mlp_classifier_hidden_layers: 100\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - norm_mode: zscore_offdiag\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - num_workers: 4\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - outer_folds: 5\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - output_dir: resultados/v1.4\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - repeated_outer_folds_n_repeats: 2\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - seed: 42\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - use_layernorm_vae_fc: True\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - vae_final_activation: tanh\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - vae_val_split_ratio: 0.15\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1023 - weight_decay_vae: 1e-05\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:1024 - ------------------------------------\n",
      "2025-06-04 17:36:53,574 - INFO - nuevo.py:350 - Cargando tensor global desde: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 17:36:54,074 - INFO - nuevo.py:358 - Tensor global cargado. Forma: (431, 6, 131, 131)\n",
      "2025-06-04 17:36:54,074 - INFO - nuevo.py:366 - Cargando metadatos desde: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 17:36:54,078 - INFO - nuevo.py:373 - Metadatos cargados. Forma: (434, 24)\n",
      "2025-06-04 17:36:54,080 - INFO - nuevo.py:563 - Usando canales seleccionados (índices en tensor original): [1, 2, 3]\n",
      "2025-06-04 17:36:54,080 - INFO - nuevo.py:564 - Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'MI_KNN_Symmetric', 'dFC_AbsDiffMean']\n",
      "2025-06-04 17:36:54,095 - WARNING - nuevo.py:605 - Columna de estratificación 'Site' no encontrada en metadatos. Se ignorará.\n",
      "2025-06-04 17:36:54,101 - INFO - nuevo.py:609 - Estratificando folds del clasificador por: ['ResearchGroup', 'Sex']\n",
      "2025-06-04 17:36:54,102 - INFO - nuevo.py:618 - Iniciando clasificación CN vs AD. Total sujetos CN/AD disponibles en metadatos y tensor: 184. CN: 89, AD: 95\n",
      "2025-06-04 17:36:54,102 - INFO - nuevo.py:627 - Usando RepeatedStratifiedKFold con 5 splits y 2 repeats.\n",
      "2025-06-04 17:36:54,102 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 1/10 ---\n",
      "2025-06-04 17:36:54,115 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 17:36:54,115 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 17:36:54,115 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 17:36:54,186 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.046, std=0.770)\n",
      "2025-06-04 17:36:54,238 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.812)\n",
      "2025-06-04 17:36:54,292 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.769)\n",
      "2025-06-04 17:36:54,307 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 17:36:54,312 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 17:36:54,312 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 17:36:55,109 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:36:55,109 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 17:36:55,109 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 17:36:55,184 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:36:55,964 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 17:36:55,965 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 17:36:56,678 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 17:36:56,678 - INFO - nuevo.py:716 - Entrenando VAE para el fold 1...\n",
      "2025-06-04 17:37:13,908 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 10/450, Train Loss: 46250.6985, Beta: 0.1600, LR: 1.00e-04, Val Loss: 44663.9964\n",
      "2025-06-04 17:37:30,719 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 20/450, Train Loss: 39632.4636, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38224.0604\n",
      "2025-06-04 17:37:47,403 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 30/450, Train Loss: 36304.7021, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35651.7182\n",
      "2025-06-04 17:38:04,181 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 40/450, Train Loss: 34203.4123, Beta: 0.6933, LR: 1.00e-04, Val Loss: 34127.8651\n",
      "2025-06-04 17:38:20,860 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 50/450, Train Loss: 32853.6725, Beta: 0.8711, LR: 1.00e-04, Val Loss: 33263.1664\n",
      "2025-06-04 17:38:37,560 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 60/450, Train Loss: 31607.9756, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32653.5559\n",
      "2025-06-04 17:38:54,163 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 70/450, Train Loss: 30605.0990, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32217.0249\n",
      "2025-06-04 17:39:10,930 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 80/450, Train Loss: 29530.2460, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31462.7322\n",
      "2025-06-04 17:39:27,694 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 90/450, Train Loss: 28774.6414, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31107.6418\n",
      "2025-06-04 17:39:44,320 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 100/450, Train Loss: 28327.5382, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30953.2904\n",
      "2025-06-04 17:40:01,086 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 110/450, Train Loss: 27744.6173, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30761.3747\n",
      "2025-06-04 17:40:17,700 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 120/450, Train Loss: 26432.7675, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30079.8458\n",
      "2025-06-04 17:40:34,347 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 130/450, Train Loss: 26024.7309, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30022.9158\n",
      "2025-06-04 17:40:51,018 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 140/450, Train Loss: 25851.2773, Beta: 0.4711, LR: 1.00e-04, Val Loss: 29911.6134\n",
      "2025-06-04 17:41:07,609 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 150/450, Train Loss: 25519.2055, Beta: 0.6489, LR: 1.00e-04, Val Loss: 29917.2203\n",
      "2025-06-04 17:41:24,280 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 160/450, Train Loss: 25410.8412, Beta: 0.8267, LR: 1.00e-05, Val Loss: 29836.4676\n",
      "2025-06-04 17:41:40,864 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 170/450, Train Loss: 25446.8565, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29764.3410\n",
      "2025-06-04 17:41:57,575 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 180/450, Train Loss: 25271.1584, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29819.3092\n",
      "2025-06-04 17:42:14,274 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 190/450, Train Loss: 25172.8187, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29774.6227\n",
      "2025-06-04 17:42:30,894 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 200/450, Train Loss: 25173.9282, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29793.9466\n",
      "2025-06-04 17:42:47,530 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 210/450, Train Loss: 25070.3502, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29758.8499\n",
      "2025-06-04 17:43:04,044 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 220/450, Train Loss: 25015.1698, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29763.1103\n",
      "2025-06-04 17:43:20,730 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 230/450, Train Loss: 24135.0499, Beta: 0.0711, LR: 1.00e-06, Val Loss: 29360.5358\n",
      "2025-06-04 17:43:37,347 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 240/450, Train Loss: 24263.3408, Beta: 0.2489, LR: 1.00e-06, Val Loss: 29421.4932\n",
      "2025-06-04 17:43:54,014 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 250/450, Train Loss: 24461.4850, Beta: 0.4267, LR: 1.00e-07, Val Loss: 29523.6237\n",
      "2025-06-04 17:43:55,665 - INFO - nuevo.py:769 - Fold 1: Early stopping VAE en epoch 251. Mejor val_loss: 29266.9104\n",
      "2025-06-04 17:43:55,666 - INFO - nuevo.py:776 - Fold 1: Cargando mejor modelo VAE con val_loss: 29266.9104\n",
      "2025-06-04 17:44:01,745 - INFO - nuevo.py:786 - Modelo VAE del fold 1 guardado en: resultados/v1.4/vae_fold_1_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 17:44:01,752 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 17:44:01,791 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 17:44:01,828 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 1 (scoring: balanced_accuracy)...\n",
      "2025-06-04 17:44:02,581 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 1: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "2025-06-04 17:44:02,587 - INFO - nuevo.py:864 - Fold 1 - Resultados Clasificador (svm):\n",
      "2025-06-04 17:44:02,587 - INFO - nuevo.py:865 -   AUC: 0.8977, PR-AUC: 0.9228, Acc: 0.8378, Bal. Acc: 0.8363\n",
      "2025-06-04 17:44:02,587 - INFO - nuevo.py:866 -   Sens (AD): 0.8947, Spec (CN): 0.7778, F1 (AD): 0.8500\n",
      "2025-06-04 17:44:02,587 - INFO - nuevo.py:873 -   Fold 1 Train (Clf) IDs Hash: 33237429bb1ab7b98399c8fee1fd0bd3\n",
      "2025-06-04 17:44:02,587 - INFO - nuevo.py:874 -   Fold 1 Test (Clf) IDs Hash: 150c24ef7d8b9da74a4d204897a8df53\n",
      "2025-06-04 17:44:02,745 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 2/10 ---\n",
      "2025-06-04 17:44:02,760 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 17:44:02,760 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 17:44:02,760 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 17:44:02,831 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.050, std=0.778)\n",
      "2025-06-04 17:44:02,887 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.056, std=0.816)\n",
      "2025-06-04 17:44:02,942 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.037, std=0.769)\n",
      "2025-06-04 17:44:02,958 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 17:44:02,960 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 17:44:02,960 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 17:44:03,729 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:44:03,729 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 17:44:03,729 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 17:44:03,793 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:44:04,551 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 17:44:04,552 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 17:44:04,780 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 17:44:04,780 - INFO - nuevo.py:716 - Entrenando VAE para el fold 2...\n",
      "2025-06-04 17:44:21,729 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 10/450, Train Loss: 46757.6618, Beta: 0.1600, LR: 1.00e-04, Val Loss: 42577.6419\n",
      "2025-06-04 17:44:38,628 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 20/450, Train Loss: 39602.6930, Beta: 0.3378, LR: 1.00e-04, Val Loss: 36163.5466\n",
      "2025-06-04 17:44:55,555 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 30/450, Train Loss: 36193.7227, Beta: 0.5156, LR: 1.00e-04, Val Loss: 33556.9833\n",
      "2025-06-04 17:45:12,398 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 40/450, Train Loss: 34280.2381, Beta: 0.6933, LR: 1.00e-04, Val Loss: 32438.5048\n",
      "2025-06-04 17:45:29,340 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 50/450, Train Loss: 32728.3559, Beta: 0.8711, LR: 1.00e-04, Val Loss: 31324.2169\n",
      "2025-06-04 17:45:46,072 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 60/450, Train Loss: 31375.0188, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30768.3447\n",
      "2025-06-04 17:46:02,909 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 70/450, Train Loss: 30517.9677, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30438.8079\n",
      "2025-06-04 17:46:19,760 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 80/450, Train Loss: 29503.1559, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29935.2375\n",
      "2025-06-04 17:46:36,637 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 90/450, Train Loss: 28919.2679, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29731.6303\n",
      "2025-06-04 17:46:53,581 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 100/450, Train Loss: 28087.7332, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29420.8431\n",
      "2025-06-04 17:47:10,494 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 110/450, Train Loss: 27861.1869, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29803.0262\n",
      "2025-06-04 17:47:27,305 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 120/450, Train Loss: 26255.2091, Beta: 0.1156, LR: 1.00e-04, Val Loss: 28587.0116\n",
      "2025-06-04 17:47:44,220 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 130/450, Train Loss: 26239.4310, Beta: 0.2933, LR: 1.00e-04, Val Loss: 28407.2171\n",
      "2025-06-04 17:48:01,017 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 140/450, Train Loss: 25775.9162, Beta: 0.4711, LR: 1.00e-04, Val Loss: 28495.9354\n",
      "2025-06-04 17:48:17,897 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 150/450, Train Loss: 25479.9816, Beta: 0.6489, LR: 1.00e-04, Val Loss: 28263.7329\n",
      "2025-06-04 17:48:34,773 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 160/450, Train Loss: 25344.8445, Beta: 0.8267, LR: 1.00e-04, Val Loss: 28444.4921\n",
      "2025-06-04 17:48:51,780 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 170/450, Train Loss: 25038.9476, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28433.6928\n",
      "2025-06-04 17:49:08,645 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 180/450, Train Loss: 24947.3430, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28281.0733\n",
      "2025-06-04 17:49:25,491 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 190/450, Train Loss: 24752.9368, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28174.0215\n",
      "2025-06-04 17:49:42,249 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 200/450, Train Loss: 24623.6146, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28191.1949\n",
      "2025-06-04 17:49:59,084 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 210/450, Train Loss: 24724.4648, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28214.7456\n",
      "2025-06-04 17:50:15,815 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 220/450, Train Loss: 24634.9318, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28195.1988\n",
      "2025-06-04 17:50:32,527 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 230/450, Train Loss: 23885.0966, Beta: 0.0711, LR: 1.00e-06, Val Loss: 27839.5740\n",
      "2025-06-04 17:50:49,327 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 240/450, Train Loss: 23894.7473, Beta: 0.2489, LR: 1.00e-06, Val Loss: 27907.4672\n",
      "2025-06-04 17:51:06,091 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 250/450, Train Loss: 24110.1520, Beta: 0.4267, LR: 1.00e-07, Val Loss: 27909.3335\n",
      "2025-06-04 17:51:09,414 - INFO - nuevo.py:769 - Fold 2: Early stopping VAE en epoch 252. Mejor val_loss: 27776.1236\n",
      "2025-06-04 17:51:09,414 - INFO - nuevo.py:776 - Fold 2: Cargando mejor modelo VAE con val_loss: 27776.1236\n",
      "2025-06-04 17:51:15,378 - INFO - nuevo.py:786 - Modelo VAE del fold 2 guardado en: resultados/v1.4/vae_fold_2_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 17:51:15,385 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 17:51:15,420 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 17:51:15,458 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 2 (scoring: balanced_accuracy)...\n",
      "2025-06-04 17:51:16,272 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 2: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 17:51:16,278 - INFO - nuevo.py:864 - Fold 2 - Resultados Clasificador (svm):\n",
      "2025-06-04 17:51:16,278 - INFO - nuevo.py:865 -   AUC: 0.7953, PR-AUC: 0.8453, Acc: 0.7297, Bal. Acc: 0.7281\n",
      "2025-06-04 17:51:16,278 - INFO - nuevo.py:866 -   Sens (AD): 0.7895, Spec (CN): 0.6667, F1 (AD): 0.7500\n",
      "2025-06-04 17:51:16,279 - INFO - nuevo.py:873 -   Fold 2 Train (Clf) IDs Hash: 34e03b78fb1b8629fe0238d65a5035b6\n",
      "2025-06-04 17:51:16,279 - INFO - nuevo.py:874 -   Fold 2 Test (Clf) IDs Hash: 120bcd18354da654194d0a44983824f6\n",
      "2025-06-04 17:51:16,390 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 3/10 ---\n",
      "2025-06-04 17:51:16,403 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 17:51:16,403 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 17:51:16,403 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 17:51:16,475 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.775)\n",
      "2025-06-04 17:51:16,532 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.812)\n",
      "2025-06-04 17:51:16,587 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.766)\n",
      "2025-06-04 17:51:16,602 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 17:51:16,604 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 17:51:16,604 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 17:51:17,376 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:51:17,376 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 17:51:17,376 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 17:51:17,452 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:51:18,206 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 17:51:18,207 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 17:51:18,450 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 17:51:18,450 - INFO - nuevo.py:716 - Entrenando VAE para el fold 3...\n",
      "2025-06-04 17:51:35,478 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 10/450, Train Loss: 46104.0654, Beta: 0.1600, LR: 1.00e-04, Val Loss: 43822.7500\n",
      "2025-06-04 17:51:52,517 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 20/450, Train Loss: 39493.4255, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38103.0818\n",
      "2025-06-04 17:52:09,539 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 30/450, Train Loss: 36051.0277, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35389.7992\n",
      "2025-06-04 17:52:26,424 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 40/450, Train Loss: 34168.4499, Beta: 0.6933, LR: 1.00e-04, Val Loss: 33951.8112\n",
      "2025-06-04 17:52:43,319 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 50/450, Train Loss: 32623.3727, Beta: 0.8711, LR: 1.00e-04, Val Loss: 33158.0323\n",
      "2025-06-04 17:53:00,257 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 60/450, Train Loss: 31279.3678, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32435.5667\n",
      "2025-06-04 17:53:17,322 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 70/450, Train Loss: 30316.5085, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32058.3875\n",
      "2025-06-04 17:53:34,287 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 80/450, Train Loss: 29589.5560, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31504.3368\n",
      "2025-06-04 17:53:51,310 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 90/450, Train Loss: 28799.6223, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31262.6944\n",
      "2025-06-04 17:54:08,261 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 100/450, Train Loss: 28353.3603, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31239.8479\n",
      "2025-06-04 17:54:25,348 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 110/450, Train Loss: 27540.9555, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30715.4585\n",
      "2025-06-04 17:54:42,445 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 120/450, Train Loss: 26601.2595, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30353.3148\n",
      "2025-06-04 17:54:59,279 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 130/450, Train Loss: 26312.2111, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30460.2388\n",
      "2025-06-04 17:55:16,326 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 140/450, Train Loss: 25801.3111, Beta: 0.4711, LR: 1.00e-04, Val Loss: 29892.1586\n",
      "2025-06-04 17:55:33,425 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 150/450, Train Loss: 25609.2006, Beta: 0.6489, LR: 1.00e-04, Val Loss: 29771.3812\n",
      "2025-06-04 17:55:50,449 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 160/450, Train Loss: 25388.6197, Beta: 0.8267, LR: 1.00e-04, Val Loss: 29836.2004\n",
      "2025-06-04 17:56:07,345 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 170/450, Train Loss: 25178.0220, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29671.0512\n",
      "2025-06-04 17:56:24,279 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 180/450, Train Loss: 24831.6758, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29508.4147\n",
      "2025-06-04 17:56:41,161 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 190/450, Train Loss: 24676.9029, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29498.3548\n",
      "2025-06-04 17:56:58,058 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 200/450, Train Loss: 24757.8591, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29556.3280\n",
      "2025-06-04 17:57:14,908 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 210/450, Train Loss: 24552.0379, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29412.9318\n",
      "2025-06-04 17:57:31,719 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 220/450, Train Loss: 24498.0970, Beta: 1.0000, LR: 1.00e-05, Val Loss: 29481.7178\n",
      "2025-06-04 17:57:48,597 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 230/450, Train Loss: 23805.7634, Beta: 0.0711, LR: 1.00e-05, Val Loss: 29039.3566\n",
      "2025-06-04 17:58:05,428 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 240/450, Train Loss: 23848.1011, Beta: 0.2489, LR: 1.00e-05, Val Loss: 29106.6422\n",
      "2025-06-04 17:58:22,245 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 250/450, Train Loss: 24008.9496, Beta: 0.4267, LR: 1.00e-06, Val Loss: 29226.3828\n",
      "2025-06-04 17:58:23,914 - INFO - nuevo.py:769 - Fold 3: Early stopping VAE en epoch 251. Mejor val_loss: 29006.1725\n",
      "2025-06-04 17:58:23,915 - INFO - nuevo.py:776 - Fold 3: Cargando mejor modelo VAE con val_loss: 29006.1725\n",
      "2025-06-04 17:58:30,039 - INFO - nuevo.py:786 - Modelo VAE del fold 3 guardado en: resultados/v1.4/vae_fold_3_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 17:58:30,048 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 17:58:30,086 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 17:58:30,121 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 3 (scoring: balanced_accuracy)...\n",
      "2025-06-04 17:58:30,897 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 3: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "2025-06-04 17:58:30,903 - INFO - nuevo.py:864 - Fold 3 - Resultados Clasificador (svm):\n",
      "2025-06-04 17:58:30,903 - INFO - nuevo.py:865 -   AUC: 0.7778, PR-AUC: 0.8200, Acc: 0.7027, Bal. Acc: 0.7032\n",
      "2025-06-04 17:58:30,903 - INFO - nuevo.py:866 -   Sens (AD): 0.6842, Spec (CN): 0.7222, F1 (AD): 0.7027\n",
      "2025-06-04 17:58:30,904 - INFO - nuevo.py:873 -   Fold 3 Train (Clf) IDs Hash: 880f3db2b89bbbc3479891e1acf54160\n",
      "2025-06-04 17:58:30,904 - INFO - nuevo.py:874 -   Fold 3 Test (Clf) IDs Hash: cd438041de3b53fc761ec2dbc9f84012\n",
      "2025-06-04 17:58:31,013 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 4/10 ---\n",
      "2025-06-04 17:58:31,026 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 17:58:31,026 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 17:58:31,026 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 17:58:31,098 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.777)\n",
      "2025-06-04 17:58:31,151 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.055, std=0.812)\n",
      "2025-06-04 17:58:31,208 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.037, std=0.768)\n",
      "2025-06-04 17:58:31,223 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 17:58:31,226 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 17:58:31,226 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 17:58:32,068 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:58:32,068 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 17:58:32,068 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 17:58:32,122 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 17:58:32,863 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 17:58:32,864 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 17:58:33,091 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 17:58:33,091 - INFO - nuevo.py:716 - Entrenando VAE para el fold 4...\n",
      "2025-06-04 17:58:50,075 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 10/450, Train Loss: 46341.4025, Beta: 0.1600, LR: 1.00e-04, Val Loss: 44186.8885\n",
      "2025-06-04 17:59:06,997 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 20/450, Train Loss: 40007.3431, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38073.6302\n",
      "2025-06-04 17:59:24,125 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 30/450, Train Loss: 36331.8837, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35308.1081\n",
      "2025-06-04 17:59:41,068 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 40/450, Train Loss: 34171.8094, Beta: 0.6933, LR: 1.00e-04, Val Loss: 33896.4284\n",
      "2025-06-04 17:59:57,997 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 50/450, Train Loss: 32628.0354, Beta: 0.8711, LR: 1.00e-04, Val Loss: 33034.3980\n",
      "2025-06-04 18:00:14,936 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 60/450, Train Loss: 31519.0914, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32471.7111\n",
      "2025-06-04 18:00:31,976 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 70/450, Train Loss: 30249.2944, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31924.5853\n",
      "2025-06-04 18:00:48,950 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 80/450, Train Loss: 29362.6265, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31618.8186\n",
      "2025-06-04 18:01:05,772 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 90/450, Train Loss: 28786.9881, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31243.8531\n",
      "2025-06-04 18:01:22,824 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 100/450, Train Loss: 28122.8371, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31190.9368\n",
      "2025-06-04 18:01:39,792 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 110/450, Train Loss: 27597.5944, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30989.4030\n",
      "2025-06-04 18:01:56,696 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 120/450, Train Loss: 26173.2024, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30135.5934\n",
      "2025-06-04 18:02:13,615 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 130/450, Train Loss: 25788.4649, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30036.1007\n",
      "2025-06-04 18:02:30,513 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 140/450, Train Loss: 25618.6257, Beta: 0.4711, LR: 1.00e-04, Val Loss: 30034.0902\n",
      "2025-06-04 18:02:47,475 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 150/450, Train Loss: 25445.4311, Beta: 0.6489, LR: 1.00e-04, Val Loss: 30002.8710\n",
      "2025-06-04 18:03:04,303 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 160/450, Train Loss: 25164.2066, Beta: 0.8267, LR: 1.00e-04, Val Loss: 29851.5451\n",
      "2025-06-04 18:03:21,352 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 170/450, Train Loss: 25089.4484, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29766.3900\n",
      "2025-06-04 18:03:38,080 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 180/450, Train Loss: 24736.7831, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29718.8405\n",
      "2025-06-04 18:03:54,914 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 190/450, Train Loss: 24396.4434, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29645.1867\n",
      "2025-06-04 18:04:11,720 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 200/450, Train Loss: 24238.4770, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29429.1301\n",
      "2025-06-04 18:04:28,502 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 210/450, Train Loss: 23778.8971, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29366.4628\n",
      "2025-06-04 18:04:45,320 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 220/450, Train Loss: 23605.6713, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29323.1966\n",
      "2025-06-04 18:05:02,318 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 230/450, Train Loss: 22585.5703, Beta: 0.0711, LR: 1.00e-04, Val Loss: 28603.1974\n",
      "2025-06-04 18:05:19,123 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 240/450, Train Loss: 22453.3569, Beta: 0.2489, LR: 1.00e-04, Val Loss: 28638.1923\n",
      "2025-06-04 18:05:35,919 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 250/450, Train Loss: 22479.2347, Beta: 0.4267, LR: 1.00e-04, Val Loss: 28729.3698\n",
      "2025-06-04 18:05:52,767 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 260/450, Train Loss: 22267.2029, Beta: 0.6044, LR: 1.00e-05, Val Loss: 28684.1629\n",
      "2025-06-04 18:06:02,923 - INFO - nuevo.py:769 - Fold 4: Early stopping VAE en epoch 266. Mejor val_loss: 28596.6230\n",
      "2025-06-04 18:06:02,923 - INFO - nuevo.py:776 - Fold 4: Cargando mejor modelo VAE con val_loss: 28596.6230\n",
      "2025-06-04 18:06:05,053 - INFO - nuevo.py:786 - Modelo VAE del fold 4 guardado en: resultados/v1.4/vae_fold_4_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:06:05,057 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 18:06:05,099 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 18:06:05,135 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 4 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:06:05,862 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 4: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:06:05,868 - INFO - nuevo.py:864 - Fold 4 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:06:05,868 - INFO - nuevo.py:865 -   AUC: 0.8158, PR-AUC: 0.8634, Acc: 0.7027, Bal. Acc: 0.6988\n",
      "2025-06-04 18:06:05,868 - INFO - nuevo.py:866 -   Sens (AD): 0.8421, Spec (CN): 0.5556, F1 (AD): 0.7442\n",
      "2025-06-04 18:06:05,869 - INFO - nuevo.py:873 -   Fold 4 Train (Clf) IDs Hash: c22989182ae2a35200820690ad2375a3\n",
      "2025-06-04 18:06:05,869 - INFO - nuevo.py:874 -   Fold 4 Test (Clf) IDs Hash: 0217f63103cf5c7c039482f935f0ca07\n",
      "2025-06-04 18:06:05,977 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 5/10 ---\n",
      "2025-06-04 18:06:05,990 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 18:06:05,990 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 18:06:05,990 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 335 sujetos de entrenamiento.\n",
      "2025-06-04 18:06:06,088 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.777)\n",
      "2025-06-04 18:06:06,145 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.056, std=0.812)\n",
      "2025-06-04 18:06:06,209 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.764)\n",
      "2025-06-04 18:06:06,226 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 18:06:06,228 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 18:06:06,228 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 18:06:07,027 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:06:07,027 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 18:06:07,027 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 18:06:07,080 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:06:07,856 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 18:06:07,857 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 18:06:08,098 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 18:06:08,098 - INFO - nuevo.py:716 - Entrenando VAE para el fold 5...\n",
      "2025-06-04 18:06:25,204 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 10/450, Train Loss: 47458.4865, Beta: 0.1600, LR: 1.00e-04, Val Loss: 47082.2318\n",
      "2025-06-04 18:06:42,262 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 20/450, Train Loss: 39864.3712, Beta: 0.3378, LR: 1.00e-04, Val Loss: 39395.2167\n",
      "2025-06-04 18:06:59,248 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 30/450, Train Loss: 36249.2144, Beta: 0.5156, LR: 1.00e-04, Val Loss: 36577.1055\n",
      "2025-06-04 18:07:16,287 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 40/450, Train Loss: 34013.7404, Beta: 0.6933, LR: 1.00e-04, Val Loss: 35249.8870\n",
      "2025-06-04 18:07:33,421 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 50/450, Train Loss: 32192.2647, Beta: 0.8711, LR: 1.00e-04, Val Loss: 34436.3167\n",
      "2025-06-04 18:07:50,349 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 60/450, Train Loss: 31085.2049, Beta: 1.0000, LR: 1.00e-04, Val Loss: 33710.8753\n",
      "2025-06-04 18:08:07,220 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 70/450, Train Loss: 30065.2738, Beta: 1.0000, LR: 1.00e-04, Val Loss: 33243.7354\n",
      "2025-06-04 18:08:24,305 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 80/450, Train Loss: 29334.0902, Beta: 1.0000, LR: 1.00e-04, Val Loss: 33133.2862\n",
      "2025-06-04 18:08:41,385 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 90/450, Train Loss: 28374.3761, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32420.2525\n",
      "2025-06-04 18:08:58,400 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 100/450, Train Loss: 27823.6111, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32326.3477\n",
      "2025-06-04 18:09:15,585 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 110/450, Train Loss: 27339.7778, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32146.7819\n",
      "2025-06-04 18:09:32,663 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 120/450, Train Loss: 26072.4556, Beta: 0.1156, LR: 1.00e-04, Val Loss: 31438.9819\n",
      "2025-06-04 18:09:49,610 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 130/450, Train Loss: 25820.6532, Beta: 0.2933, LR: 1.00e-04, Val Loss: 31407.2617\n",
      "2025-06-04 18:10:06,644 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 140/450, Train Loss: 25369.5277, Beta: 0.4711, LR: 1.00e-04, Val Loss: 31171.6708\n",
      "2025-06-04 18:10:23,623 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 150/450, Train Loss: 25394.9392, Beta: 0.6489, LR: 1.00e-04, Val Loss: 31128.9587\n",
      "2025-06-04 18:10:40,637 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 160/450, Train Loss: 25206.1415, Beta: 0.8267, LR: 1.00e-04, Val Loss: 31301.4811\n",
      "2025-06-04 18:10:57,671 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 170/450, Train Loss: 24910.2813, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31192.1155\n",
      "2025-06-04 18:11:14,561 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 180/450, Train Loss: 24649.7734, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31038.6658\n",
      "2025-06-04 18:11:31,397 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 190/450, Train Loss: 24577.7810, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31039.1121\n",
      "2025-06-04 18:11:48,243 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 200/450, Train Loss: 24609.1777, Beta: 1.0000, LR: 1.00e-06, Val Loss: 31047.7328\n",
      "2025-06-04 18:12:05,149 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 210/450, Train Loss: 24557.2502, Beta: 1.0000, LR: 1.00e-06, Val Loss: 31013.0526\n",
      "2025-06-04 18:12:22,126 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 220/450, Train Loss: 24572.9983, Beta: 1.0000, LR: 1.00e-07, Val Loss: 31032.1911\n",
      "2025-06-04 18:12:39,072 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 230/450, Train Loss: 23634.0358, Beta: 0.0711, LR: 1.00e-07, Val Loss: 30627.4909\n",
      "2025-06-04 18:12:56,003 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 240/450, Train Loss: 23878.0799, Beta: 0.2489, LR: 1.00e-07, Val Loss: 30697.5829\n",
      "2025-06-04 18:13:12,922 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 250/450, Train Loss: 24175.9418, Beta: 0.4267, LR: 1.00e-08, Val Loss: 30848.9836\n",
      "2025-06-04 18:13:16,321 - INFO - nuevo.py:769 - Fold 5: Early stopping VAE en epoch 252. Mejor val_loss: 30575.0625\n",
      "2025-06-04 18:13:16,321 - INFO - nuevo.py:776 - Fold 5: Cargando mejor modelo VAE con val_loss: 30575.0625\n",
      "2025-06-04 18:13:18,435 - INFO - nuevo.py:786 - Modelo VAE del fold 5 guardado en: resultados/v1.4/vae_fold_5_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:13:18,441 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (148 sujetos, 3 canales).\n",
      "2025-06-04 18:13:18,477 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (36 sujetos, 3 canales).\n",
      "2025-06-04 18:13:18,516 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 5 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:13:19,246 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 5: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:13:19,251 - INFO - nuevo.py:864 - Fold 5 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:13:19,251 - INFO - nuevo.py:865 -   AUC: 0.7152, PR-AUC: 0.7270, Acc: 0.6944, Bal. Acc: 0.6981\n",
      "2025-06-04 18:13:19,251 - INFO - nuevo.py:866 -   Sens (AD): 0.6316, Spec (CN): 0.7647, F1 (AD): 0.6857\n",
      "2025-06-04 18:13:19,252 - INFO - nuevo.py:873 -   Fold 5 Train (Clf) IDs Hash: 1ad182a139a4bab496c7cb46246faa69\n",
      "2025-06-04 18:13:19,252 - INFO - nuevo.py:874 -   Fold 5 Test (Clf) IDs Hash: c75bad004aa9a6304767ba0f099959b9\n",
      "2025-06-04 18:13:19,358 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 6/10 ---\n",
      "2025-06-04 18:13:19,370 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 18:13:19,370 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 18:13:19,370 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 18:13:19,446 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.776)\n",
      "2025-06-04 18:13:19,509 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.059, std=0.814)\n",
      "2025-06-04 18:13:19,566 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.035, std=0.768)\n",
      "2025-06-04 18:13:19,581 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 18:13:19,583 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 18:13:19,583 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 18:13:20,381 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:13:20,381 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 18:13:20,381 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 18:13:20,439 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:13:21,205 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 18:13:21,206 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 18:13:21,431 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 18:13:21,431 - INFO - nuevo.py:716 - Entrenando VAE para el fold 6...\n",
      "2025-06-04 18:13:38,667 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 10/450, Train Loss: 46530.9695, Beta: 0.1600, LR: 1.00e-04, Val Loss: 43870.4242\n",
      "2025-06-04 18:13:55,963 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 20/450, Train Loss: 40009.8813, Beta: 0.3378, LR: 1.00e-04, Val Loss: 37593.9016\n",
      "2025-06-04 18:14:13,127 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 30/450, Train Loss: 36197.4169, Beta: 0.5156, LR: 1.00e-04, Val Loss: 34650.4716\n",
      "2025-06-04 18:14:30,697 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 40/450, Train Loss: 33962.1454, Beta: 0.6933, LR: 1.00e-04, Val Loss: 33231.9611\n",
      "2025-06-04 18:14:47,964 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 50/450, Train Loss: 32427.4241, Beta: 0.8711, LR: 1.00e-04, Val Loss: 32256.7848\n",
      "2025-06-04 18:15:05,238 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 60/450, Train Loss: 31508.5809, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31730.5901\n",
      "2025-06-04 18:15:22,484 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 70/450, Train Loss: 30213.0427, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31002.3361\n",
      "2025-06-04 18:15:39,751 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 80/450, Train Loss: 29500.5167, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30844.3561\n",
      "2025-06-04 18:15:56,959 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 90/450, Train Loss: 28661.8243, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30339.5923\n",
      "2025-06-04 18:16:14,254 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 100/450, Train Loss: 28001.1155, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30000.4358\n",
      "2025-06-04 18:16:31,391 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 110/450, Train Loss: 27699.7114, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29955.4219\n",
      "2025-06-04 18:16:48,745 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 120/450, Train Loss: 26350.1126, Beta: 0.1156, LR: 1.00e-04, Val Loss: 29057.9207\n",
      "2025-06-04 18:17:05,960 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 130/450, Train Loss: 26001.7273, Beta: 0.2933, LR: 1.00e-04, Val Loss: 29108.4117\n",
      "2025-06-04 18:17:23,329 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 140/450, Train Loss: 25693.8140, Beta: 0.4711, LR: 1.00e-04, Val Loss: 29110.0495\n",
      "2025-06-04 18:17:40,698 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 150/450, Train Loss: 25547.4663, Beta: 0.6489, LR: 1.00e-04, Val Loss: 29097.4443\n",
      "2025-06-04 18:17:58,084 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 160/450, Train Loss: 25398.9638, Beta: 0.8267, LR: 1.00e-05, Val Loss: 28988.2755\n",
      "2025-06-04 18:18:15,631 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 170/450, Train Loss: 25406.1478, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28910.6488\n",
      "2025-06-04 18:18:32,658 - INFO - nuevo.py:773 - Fold 6, VAE Epoch 180/450, Train Loss: 25268.8554, Beta: 1.0000, LR: 1.00e-06, Val Loss: 28935.1167\n",
      "2025-06-04 18:18:46,193 - INFO - nuevo.py:769 - Fold 6: Early stopping VAE en epoch 188. Mejor val_loss: 28882.5516\n",
      "2025-06-04 18:18:46,194 - INFO - nuevo.py:776 - Fold 6: Cargando mejor modelo VAE con val_loss: 28882.5516\n",
      "2025-06-04 18:18:48,302 - INFO - nuevo.py:786 - Modelo VAE del fold 6 guardado en: resultados/v1.4/vae_fold_6_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:18:48,311 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 18:18:48,349 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 18:18:48,383 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 6 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:18:49,213 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 6: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:18:49,219 - INFO - nuevo.py:864 - Fold 6 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:18:49,219 - INFO - nuevo.py:865 -   AUC: 0.8743, PR-AUC: 0.9144, Acc: 0.8108, Bal. Acc: 0.8099\n",
      "2025-06-04 18:18:49,219 - INFO - nuevo.py:866 -   Sens (AD): 0.8421, Spec (CN): 0.7778, F1 (AD): 0.8205\n",
      "2025-06-04 18:18:49,220 - INFO - nuevo.py:873 -   Fold 6 Train (Clf) IDs Hash: cbfc21ce4215da33b8982159066d9d93\n",
      "2025-06-04 18:18:49,220 - INFO - nuevo.py:874 -   Fold 6 Test (Clf) IDs Hash: b901929ca1be2af17015a05fc18fac10\n",
      "2025-06-04 18:18:49,336 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 7/10 ---\n",
      "2025-06-04 18:18:49,350 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 18:18:49,351 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 18:18:49,351 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 18:18:49,448 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.046, std=0.774)\n",
      "2025-06-04 18:18:49,510 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.057, std=0.811)\n",
      "2025-06-04 18:18:49,564 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.035, std=0.768)\n",
      "2025-06-04 18:18:49,578 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 18:18:49,581 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 18:18:49,581 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 18:18:50,427 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:18:50,427 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 18:18:50,427 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 18:18:50,481 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:18:51,276 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 18:18:51,276 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 18:18:51,518 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 18:18:51,519 - INFO - nuevo.py:716 - Entrenando VAE para el fold 7...\n",
      "2025-06-04 18:19:08,591 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 10/450, Train Loss: 46463.4500, Beta: 0.1600, LR: 1.00e-04, Val Loss: 44826.2479\n",
      "2025-06-04 18:19:25,587 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 20/450, Train Loss: 39948.4585, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38664.1901\n",
      "2025-06-04 18:19:43,024 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 30/450, Train Loss: 36413.3368, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35914.4005\n",
      "2025-06-04 18:20:00,057 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 40/450, Train Loss: 34375.9075, Beta: 0.6933, LR: 1.00e-04, Val Loss: 34522.7576\n",
      "2025-06-04 18:20:17,313 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 50/450, Train Loss: 32687.8526, Beta: 0.8711, LR: 1.00e-04, Val Loss: 33506.9794\n",
      "2025-06-04 18:20:34,679 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 60/450, Train Loss: 31760.1193, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32782.8924\n",
      "2025-06-04 18:20:51,982 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 70/450, Train Loss: 30364.6616, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32051.0133\n",
      "2025-06-04 18:21:09,391 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 80/450, Train Loss: 29584.7611, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31775.9626\n",
      "2025-06-04 18:21:26,906 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 90/450, Train Loss: 28636.7794, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31604.4957\n",
      "2025-06-04 18:21:44,255 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 100/450, Train Loss: 28127.3370, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31248.2212\n",
      "2025-06-04 18:22:01,607 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 110/450, Train Loss: 27616.0964, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30976.4763\n",
      "2025-06-04 18:22:18,843 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 120/450, Train Loss: 26165.4114, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30398.4902\n",
      "2025-06-04 18:22:36,303 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 130/450, Train Loss: 26019.4397, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30125.5835\n",
      "2025-06-04 18:22:53,920 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 140/450, Train Loss: 25759.6386, Beta: 0.4711, LR: 1.00e-04, Val Loss: 30152.0391\n",
      "2025-06-04 18:23:11,445 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 150/450, Train Loss: 25444.7915, Beta: 0.6489, LR: 1.00e-04, Val Loss: 30123.9874\n",
      "2025-06-04 18:23:28,735 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 160/450, Train Loss: 25320.5183, Beta: 0.8267, LR: 1.00e-04, Val Loss: 30008.2646\n",
      "2025-06-04 18:23:46,118 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 170/450, Train Loss: 25076.0083, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29951.7195\n",
      "2025-06-04 18:24:03,288 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 180/450, Train Loss: 24822.3812, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29837.1383\n",
      "2025-06-04 18:24:20,493 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 190/450, Train Loss: 24482.5802, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29721.5341\n",
      "2025-06-04 18:24:37,469 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 200/450, Train Loss: 24170.4980, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29694.6799\n",
      "2025-06-04 18:24:54,482 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 210/450, Train Loss: 24020.1384, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29706.9579\n",
      "2025-06-04 18:25:11,482 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 220/450, Train Loss: 23643.7636, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29532.9009\n",
      "2025-06-04 18:25:28,436 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 230/450, Train Loss: 22560.5606, Beta: 0.0711, LR: 1.00e-04, Val Loss: 28911.1180\n",
      "2025-06-04 18:25:45,390 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 240/450, Train Loss: 22431.6796, Beta: 0.2489, LR: 1.00e-04, Val Loss: 28840.7452\n",
      "2025-06-04 18:26:02,216 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 250/450, Train Loss: 22485.9462, Beta: 0.4267, LR: 1.00e-04, Val Loss: 28891.5924\n",
      "2025-06-04 18:26:19,137 - INFO - nuevo.py:773 - Fold 7, VAE Epoch 260/450, Train Loss: 22537.1628, Beta: 0.6044, LR: 1.00e-05, Val Loss: 28929.8056\n",
      "2025-06-04 18:26:22,561 - INFO - nuevo.py:769 - Fold 7: Early stopping VAE en epoch 262. Mejor val_loss: 28823.7076\n",
      "2025-06-04 18:26:22,561 - INFO - nuevo.py:776 - Fold 7: Cargando mejor modelo VAE con val_loss: 28823.7076\n",
      "2025-06-04 18:26:24,748 - INFO - nuevo.py:786 - Modelo VAE del fold 7 guardado en: resultados/v1.4/vae_fold_7_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:26:24,757 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 18:26:24,788 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 18:26:24,829 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 7 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:26:25,592 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 7: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:26:25,597 - INFO - nuevo.py:864 - Fold 7 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:26:25,598 - INFO - nuevo.py:865 -   AUC: 0.6901, PR-AUC: 0.7285, Acc: 0.6216, Bal. Acc: 0.6184\n",
      "2025-06-04 18:26:25,598 - INFO - nuevo.py:866 -   Sens (AD): 0.7368, Spec (CN): 0.5000, F1 (AD): 0.6667\n",
      "2025-06-04 18:26:25,598 - INFO - nuevo.py:873 -   Fold 7 Train (Clf) IDs Hash: 8c739bc47b2bb5648ac2906cbf3f6cac\n",
      "2025-06-04 18:26:25,598 - INFO - nuevo.py:874 -   Fold 7 Test (Clf) IDs Hash: 9b60bbd05b536a24068346a351264ccb\n",
      "2025-06-04 18:26:25,723 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 8/10 ---\n",
      "2025-06-04 18:26:25,736 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 18:26:25,736 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 18:26:25,737 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 18:26:25,808 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.777)\n",
      "2025-06-04 18:26:25,865 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.812)\n",
      "2025-06-04 18:26:25,922 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.768)\n",
      "2025-06-04 18:26:25,936 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 18:26:25,939 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 18:26:25,939 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 18:26:26,736 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:26:26,736 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 18:26:26,736 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 18:26:26,796 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:26:27,545 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 18:26:27,545 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 18:26:27,784 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 18:26:27,784 - INFO - nuevo.py:716 - Entrenando VAE para el fold 8...\n",
      "2025-06-04 18:26:44,857 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 10/450, Train Loss: 47001.8314, Beta: 0.1600, LR: 1.00e-04, Val Loss: 44359.5904\n",
      "2025-06-04 18:27:01,824 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 20/450, Train Loss: 40014.7765, Beta: 0.3378, LR: 1.00e-04, Val Loss: 37359.3589\n",
      "2025-06-04 18:27:18,943 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 30/450, Train Loss: 36159.5802, Beta: 0.5156, LR: 1.00e-04, Val Loss: 34688.3560\n",
      "2025-06-04 18:27:36,049 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 40/450, Train Loss: 34060.8541, Beta: 0.6933, LR: 1.00e-04, Val Loss: 32725.6823\n",
      "2025-06-04 18:27:53,190 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 50/450, Train Loss: 32702.1730, Beta: 0.8711, LR: 1.00e-04, Val Loss: 31982.9887\n",
      "2025-06-04 18:28:10,188 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 60/450, Train Loss: 31275.0921, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31343.5457\n",
      "2025-06-04 18:28:27,446 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 70/450, Train Loss: 30091.4783, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30682.8432\n",
      "2025-06-04 18:28:44,695 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 80/450, Train Loss: 29380.4250, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30323.8207\n",
      "2025-06-04 18:29:02,009 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 90/450, Train Loss: 28579.4304, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30109.5171\n",
      "2025-06-04 18:29:19,252 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 100/450, Train Loss: 27870.5539, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29805.8780\n",
      "2025-06-04 18:29:36,318 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 110/450, Train Loss: 27600.9047, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29915.2329\n",
      "2025-06-04 18:29:53,332 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 120/450, Train Loss: 26469.5664, Beta: 0.1156, LR: 1.00e-04, Val Loss: 29009.1107\n",
      "2025-06-04 18:30:10,479 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 130/450, Train Loss: 26040.0325, Beta: 0.2933, LR: 1.00e-04, Val Loss: 29221.6111\n",
      "2025-06-04 18:30:27,644 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 140/450, Train Loss: 25633.3405, Beta: 0.4711, LR: 1.00e-04, Val Loss: 28845.8258\n",
      "2025-06-04 18:30:44,730 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 150/450, Train Loss: 25652.9754, Beta: 0.6489, LR: 1.00e-04, Val Loss: 28792.6483\n",
      "2025-06-04 18:31:01,753 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 160/450, Train Loss: 25243.8851, Beta: 0.8267, LR: 1.00e-04, Val Loss: 28607.4266\n",
      "2025-06-04 18:31:18,791 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 170/450, Train Loss: 25112.5513, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28813.5678\n",
      "2025-06-04 18:31:35,759 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 180/450, Train Loss: 24877.5574, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28587.7810\n",
      "2025-06-04 18:31:52,751 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 190/450, Train Loss: 24484.9559, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28349.6102\n",
      "2025-06-04 18:32:09,596 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 200/450, Train Loss: 24371.6993, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28390.9046\n",
      "2025-06-04 18:32:26,457 - INFO - nuevo.py:773 - Fold 8, VAE Epoch 210/450, Train Loss: 24362.9722, Beta: 1.0000, LR: 1.00e-06, Val Loss: 28454.2637\n",
      "2025-06-04 18:32:34,868 - INFO - nuevo.py:769 - Fold 8: Early stopping VAE en epoch 215. Mejor val_loss: 28349.6102\n",
      "2025-06-04 18:32:34,868 - INFO - nuevo.py:776 - Fold 8: Cargando mejor modelo VAE con val_loss: 28349.6102\n",
      "2025-06-04 18:32:37,038 - INFO - nuevo.py:786 - Modelo VAE del fold 8 guardado en: resultados/v1.4/vae_fold_8_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:32:37,047 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 18:32:37,081 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 18:32:37,117 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 8 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:32:37,856 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 8: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:32:37,863 - INFO - nuevo.py:864 - Fold 8 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:32:37,863 - INFO - nuevo.py:865 -   AUC: 0.8684, PR-AUC: 0.8912, Acc: 0.8649, Bal. Acc: 0.8655\n",
      "2025-06-04 18:32:37,863 - INFO - nuevo.py:866 -   Sens (AD): 0.8421, Spec (CN): 0.8889, F1 (AD): 0.8649\n",
      "2025-06-04 18:32:37,864 - INFO - nuevo.py:873 -   Fold 8 Train (Clf) IDs Hash: 24e9c9e02c0ac08735b848067078bb84\n",
      "2025-06-04 18:32:37,864 - INFO - nuevo.py:874 -   Fold 8 Test (Clf) IDs Hash: 16621ae971934e59e13e1977b0344419\n",
      "2025-06-04 18:32:37,976 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 9/10 ---\n",
      "2025-06-04 18:32:37,990 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 18:32:37,990 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 18:32:37,990 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 18:32:38,092 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.048, std=0.779)\n",
      "2025-06-04 18:32:38,147 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.054, std=0.814)\n",
      "2025-06-04 18:32:38,206 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.034, std=0.769)\n",
      "2025-06-04 18:32:38,222 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 18:32:38,225 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 18:32:38,225 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 18:32:38,995 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:32:38,996 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 18:32:38,996 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 18:32:39,051 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:32:39,873 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 18:32:39,873 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 18:32:40,166 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 18:32:40,166 - INFO - nuevo.py:716 - Entrenando VAE para el fold 9...\n",
      "2025-06-04 18:32:57,349 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 10/450, Train Loss: 46181.5238, Beta: 0.1600, LR: 1.00e-04, Val Loss: 42565.2078\n",
      "2025-06-04 18:33:14,422 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 20/450, Train Loss: 39114.0953, Beta: 0.3378, LR: 1.00e-04, Val Loss: 36320.1904\n",
      "2025-06-04 18:33:31,400 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 30/450, Train Loss: 36006.5080, Beta: 0.5156, LR: 1.00e-04, Val Loss: 33950.0685\n",
      "2025-06-04 18:33:48,498 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 40/450, Train Loss: 34011.4116, Beta: 0.6933, LR: 1.00e-04, Val Loss: 32593.2156\n",
      "2025-06-04 18:34:05,652 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 50/450, Train Loss: 32784.2427, Beta: 0.8711, LR: 1.00e-04, Val Loss: 31876.8034\n",
      "2025-06-04 18:34:22,800 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 60/450, Train Loss: 31523.8227, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31123.4652\n",
      "2025-06-04 18:34:39,949 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 70/450, Train Loss: 30406.4538, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30658.0314\n",
      "2025-06-04 18:34:57,061 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 80/450, Train Loss: 29390.0120, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30346.3900\n",
      "2025-06-04 18:35:14,133 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 90/450, Train Loss: 28894.4671, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30091.3685\n",
      "2025-06-04 18:35:31,180 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 100/450, Train Loss: 28278.5613, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29700.1405\n",
      "2025-06-04 18:35:48,337 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 110/450, Train Loss: 27684.6150, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29609.1560\n",
      "2025-06-04 18:36:05,431 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 120/450, Train Loss: 26319.8142, Beta: 0.1156, LR: 1.00e-04, Val Loss: 28915.3501\n",
      "2025-06-04 18:36:22,397 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 130/450, Train Loss: 25984.8749, Beta: 0.2933, LR: 1.00e-04, Val Loss: 28839.8521\n",
      "2025-06-04 18:36:39,380 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 140/450, Train Loss: 25916.3914, Beta: 0.4711, LR: 1.00e-04, Val Loss: 28728.3458\n",
      "2025-06-04 18:36:56,328 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 150/450, Train Loss: 25621.6826, Beta: 0.6489, LR: 1.00e-04, Val Loss: 28660.0430\n",
      "2025-06-04 18:37:13,333 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 160/450, Train Loss: 25606.2616, Beta: 0.8267, LR: 1.00e-04, Val Loss: 28756.7801\n",
      "2025-06-04 18:37:30,141 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 170/450, Train Loss: 25060.1481, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28722.7844\n",
      "2025-06-04 18:37:46,939 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 180/450, Train Loss: 24723.7002, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28454.6000\n",
      "2025-06-04 18:38:03,913 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 190/450, Train Loss: 24682.1648, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28366.7371\n",
      "2025-06-04 18:38:20,829 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 200/450, Train Loss: 24581.9039, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28404.5555\n",
      "2025-06-04 18:38:37,712 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 210/450, Train Loss: 24552.4534, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28427.0355\n",
      "2025-06-04 18:38:54,565 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 220/450, Train Loss: 24511.4866, Beta: 1.0000, LR: 1.00e-05, Val Loss: 28441.8876\n",
      "2025-06-04 18:39:11,580 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 230/450, Train Loss: 23706.8942, Beta: 0.0711, LR: 1.00e-05, Val Loss: 28039.5154\n",
      "2025-06-04 18:39:28,810 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 240/450, Train Loss: 23610.8310, Beta: 0.2489, LR: 1.00e-05, Val Loss: 28042.2375\n",
      "2025-06-04 18:39:45,969 - INFO - nuevo.py:773 - Fold 9, VAE Epoch 250/450, Train Loss: 23880.9746, Beta: 0.4267, LR: 1.00e-06, Val Loss: 28069.8698\n",
      "2025-06-04 18:39:47,694 - INFO - nuevo.py:769 - Fold 9: Early stopping VAE en epoch 251. Mejor val_loss: 27898.1174\n",
      "2025-06-04 18:39:47,694 - INFO - nuevo.py:776 - Fold 9: Cargando mejor modelo VAE con val_loss: 27898.1174\n",
      "2025-06-04 18:39:49,816 - INFO - nuevo.py:786 - Modelo VAE del fold 9 guardado en: resultados/v1.4/vae_fold_9_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:39:49,820 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 18:39:49,856 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 18:39:49,899 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 9 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:39:50,671 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 9: {'C': 100, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:39:50,676 - INFO - nuevo.py:864 - Fold 9 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:39:50,676 - INFO - nuevo.py:865 -   AUC: 0.6637, PR-AUC: 0.7096, Acc: 0.6486, Bal. Acc: 0.6462\n",
      "2025-06-04 18:39:50,676 - INFO - nuevo.py:866 -   Sens (AD): 0.7368, Spec (CN): 0.5556, F1 (AD): 0.6829\n",
      "2025-06-04 18:39:50,677 - INFO - nuevo.py:873 -   Fold 9 Train (Clf) IDs Hash: dd6e1737000eb1f2352b8138790cbc07\n",
      "2025-06-04 18:39:50,677 - INFO - nuevo.py:874 -   Fold 9 Test (Clf) IDs Hash: 6449e4fefba73e7983dda49b7260b2c9\n",
      "2025-06-04 18:39:50,785 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 10/10 ---\n",
      "2025-06-04 18:39:50,798 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 18:39:50,798 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 18:39:50,798 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 335 sujetos de entrenamiento.\n",
      "2025-06-04 18:39:50,876 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.048, std=0.779)\n",
      "2025-06-04 18:39:50,931 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.057, std=0.815)\n",
      "2025-06-04 18:39:50,988 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.035, std=0.767)\n",
      "2025-06-04 18:39:51,005 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 18:39:51,008 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 18:39:51,008 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 18:39:51,788 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:39:51,788 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 9248.\n",
      "2025-06-04 18:39:51,788 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 4624 (current is 512).\n",
      "2025-06-04 18:39:51,844 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 9248. Using LayerNorm: True\n",
      "2025-06-04 18:39:52,605 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 18:39:52,606 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 18:39:52,836 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 18:39:52,836 - INFO - nuevo.py:716 - Entrenando VAE para el fold 10...\n",
      "2025-06-04 18:40:09,949 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 10/450, Train Loss: 46774.5756, Beta: 0.1600, LR: 1.00e-04, Val Loss: 43656.8107\n",
      "2025-06-04 18:40:27,141 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 20/450, Train Loss: 39296.2708, Beta: 0.3378, LR: 1.00e-04, Val Loss: 36880.6177\n",
      "2025-06-04 18:40:44,269 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 30/450, Train Loss: 36009.3268, Beta: 0.5156, LR: 1.00e-04, Val Loss: 34453.5422\n",
      "2025-06-04 18:41:01,310 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 40/450, Train Loss: 34136.3241, Beta: 0.6933, LR: 1.00e-04, Val Loss: 33154.3500\n",
      "2025-06-04 18:41:18,474 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 50/450, Train Loss: 32715.2076, Beta: 0.8711, LR: 1.00e-04, Val Loss: 32183.1742\n",
      "2025-06-04 18:41:35,536 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 60/450, Train Loss: 31341.8876, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31485.3241\n",
      "2025-06-04 18:41:52,697 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 70/450, Train Loss: 30359.1213, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31093.5423\n",
      "2025-06-04 18:42:09,870 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 80/450, Train Loss: 29424.0634, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30615.0948\n",
      "2025-06-04 18:42:26,935 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 90/450, Train Loss: 28560.4158, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30122.4618\n",
      "2025-06-04 18:42:43,954 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 100/450, Train Loss: 28155.2556, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30085.3081\n",
      "2025-06-04 18:43:01,169 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 110/450, Train Loss: 27502.6925, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30073.2786\n",
      "2025-06-04 18:43:18,399 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 120/450, Train Loss: 26205.4016, Beta: 0.1156, LR: 1.00e-04, Val Loss: 29146.5615\n",
      "2025-06-04 18:43:35,414 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 130/450, Train Loss: 25963.0593, Beta: 0.2933, LR: 1.00e-04, Val Loss: 29077.9772\n",
      "2025-06-04 18:43:52,451 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 140/450, Train Loss: 25631.2999, Beta: 0.4711, LR: 1.00e-04, Val Loss: 29108.3949\n",
      "2025-06-04 18:44:09,752 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 150/450, Train Loss: 25532.7011, Beta: 0.6489, LR: 1.00e-04, Val Loss: 28802.3842\n",
      "2025-06-04 18:44:26,819 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 160/450, Train Loss: 25224.4403, Beta: 0.8267, LR: 1.00e-04, Val Loss: 28839.3807\n",
      "2025-06-04 18:44:43,933 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 170/450, Train Loss: 24878.0281, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28972.2587\n",
      "2025-06-04 18:45:00,957 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 180/450, Train Loss: 24800.7735, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28704.1901\n",
      "2025-06-04 18:45:18,058 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 190/450, Train Loss: 24437.6569, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28647.9419\n",
      "2025-06-04 18:45:35,066 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 200/450, Train Loss: 24046.7847, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28606.0591\n",
      "2025-06-04 18:45:52,029 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 210/450, Train Loss: 23804.0329, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28395.4475\n",
      "2025-06-04 18:46:08,916 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 220/450, Train Loss: 23650.7023, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28243.0561\n",
      "2025-06-04 18:46:25,947 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 230/450, Train Loss: 22549.5713, Beta: 0.0711, LR: 1.00e-04, Val Loss: 27701.0357\n",
      "2025-06-04 18:46:42,984 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 240/450, Train Loss: 22315.9411, Beta: 0.2489, LR: 1.00e-04, Val Loss: 27699.7868\n",
      "2025-06-04 18:46:59,991 - INFO - nuevo.py:773 - Fold 10, VAE Epoch 250/450, Train Loss: 22487.1192, Beta: 0.4267, LR: 1.00e-04, Val Loss: 27759.8591\n",
      "2025-06-04 18:47:17,045 - INFO - nuevo.py:769 - Fold 10: Early stopping VAE en epoch 260. Mejor val_loss: 27648.6497\n",
      "2025-06-04 18:47:17,045 - INFO - nuevo.py:776 - Fold 10: Cargando mejor modelo VAE con val_loss: 27648.6497\n",
      "2025-06-04 18:47:19,251 - INFO - nuevo.py:786 - Modelo VAE del fold 10 guardado en: resultados/v1.4/vae_fold_10_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 18:47:19,257 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (148 sujetos, 3 canales).\n",
      "2025-06-04 18:47:19,291 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (36 sujetos, 3 canales).\n",
      "2025-06-04 18:47:19,345 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 10 (scoring: balanced_accuracy)...\n",
      "2025-06-04 18:47:20,085 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 10: {'C': 100, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 18:47:20,089 - INFO - nuevo.py:864 - Fold 10 - Resultados Clasificador (svm):\n",
      "2025-06-04 18:47:20,090 - INFO - nuevo.py:865 -   AUC: 0.8576, PR-AUC: 0.8957, Acc: 0.7778, Bal. Acc: 0.7709\n",
      "2025-06-04 18:47:20,090 - INFO - nuevo.py:866 -   Sens (AD): 0.8947, Spec (CN): 0.6471, F1 (AD): 0.8095\n",
      "2025-06-04 18:47:20,090 - INFO - nuevo.py:873 -   Fold 10 Train (Clf) IDs Hash: a8f14e7ee0f7cd3a38ff787503361a15\n",
      "2025-06-04 18:47:20,090 - INFO - nuevo.py:874 -   Fold 10 Test (Clf) IDs Hash: f046b4c0d12512fa4d71fd36d98f7925\n",
      "2025-06-04 18:47:20,202 - INFO - nuevo.py:890 - \n",
      "--- Resumen de Rendimiento (Promedio sobre Folds Externos) ---\n",
      "2025-06-04 18:47:20,202 - INFO - nuevo.py:895 - Auc                 : 0.7956 +/- 0.0826\n",
      "2025-06-04 18:47:20,202 - INFO - nuevo.py:895 - Pr_auc              : 0.8318 +/- 0.0821\n",
      "2025-06-04 18:47:20,202 - INFO - nuevo.py:895 - Accuracy            : 0.7391 +/- 0.0809\n",
      "2025-06-04 18:47:20,203 - INFO - nuevo.py:895 - Balanced_accuracy   : 0.7375 +/- 0.0812\n",
      "2025-06-04 18:47:20,203 - INFO - nuevo.py:895 - Sensitivity         : 0.7895 +/- 0.0895\n",
      "2025-06-04 18:47:20,203 - INFO - nuevo.py:895 - Specificity         : 0.6856 +/- 0.1229\n",
      "2025-06-04 18:47:20,203 - INFO - nuevo.py:895 - F1_score            : 0.7577 +/- 0.0738\n",
      "2025-06-04 18:47:20,204 - INFO - nuevo.py:916 - Resultados de clasificación guardados en: resultados/v1.4/clf_results_svm_vae_zscore_offdiag_ld512_beta1.0_cycBeta4_ch3sel_intFChalf_dropVAE0.2_lnFCTrue_esVAE25_outer5x2_scorebalanced_accuracy.csv\n",
      "2025-06-04 18:47:20,214 - INFO - nuevo.py:925 - Sumario estadístico de métricas guardado en: resultados/v1.4/summary_stats_clf_results_svm_vae_zscore_offdiag_ld512_beta1.0_cycBeta4_ch3sel_intFChalf_dropVAE0.2_lnFCTrue_esVAE25_outer5x2_scorebalanced_accuracy.txt\n",
      "2025-06-04 18:47:20,220 - INFO - nuevo.py:1034 - Pipeline completado.\n",
      "2025-06-04 18:47:20,220 - INFO - nuevo.py:1035 - --- Consideraciones sobre Normalización y Activación Final del VAE (Recordatorio) ---\n",
      "2025-06-04 18:47:20,220 - INFO - nuevo.py:1036 - Normalización: 'minmax_offdiag' -> [0,1] (ideal con sigmoid), 'zscore_offdiag' -> media 0, std 1 (mejor con tanh/linear).\n",
      "2025-06-04 18:47:20,220 - INFO - nuevo.py:1037 - Activación Final VAE: 'sigmoid' -> [0,1], 'tanh' -> [-1,1], 'linear' -> sin restricción.\n",
      "2025-06-04 18:47:20,220 - INFO - nuevo.py:1038 - Asegurar compatibilidad entre normalización y activación es clave.\n"
     ]
    }
   ],
   "source": [
    "!python nuevo.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path      /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv \\\n",
    "    --output_dir resultados/v1.4 \\\n",
    "    --channels_to_use 1 2 3 \\\n",
    "    --outer_folds 5 \\\n",
    "    --repeated_outer_folds_n_repeats 2 \\\n",
    "    --inner_folds 3 \\\n",
    "    --classifier_stratify_cols Sex Site \\\n",
    "    --latent_dim 512 \\\n",
    "    --lr_vae 1e-4 \\\n",
    "    --epochs_vae 450 \\\n",
    "    --batch_size 32 \\\n",
    "    --beta_vae 1.0 \\\n",
    "    --cyclical_beta_n_cycles 4 \\\n",
    "    --cyclical_beta_ratio_increase 0.5 \\\n",
    "    --weight_decay_vae 1e-5 \\\n",
    "    --vae_final_activation tanh \\\n",
    "    --intermediate_fc_dim_vae half \\\n",
    "    --dropout_rate_vae 0.2 \\\n",
    "    --use_layernorm_vae_fc \\\n",
    "    --vae_val_split_ratio 0.15 \\\n",
    "    --early_stopping_patience_vae 25 \\\n",
    "    --lr_scheduler_patience_vae 15 \\\n",
    "    --classifier_type svm \\\n",
    "    --gridsearch_scoring balanced_accuracy \\\n",
    "    --classifier_use_class_weight \\\n",
    "    --norm_mode zscore_offdiag \\\n",
    "    --seed 42 \\\n",
    "    --num_workers 4 \\\n",
    "    --log_interval_epochs_vae 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
