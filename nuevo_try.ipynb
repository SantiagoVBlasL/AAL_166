{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2719512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: no es un repositorio git (ni ninguno de los directorios superiores): .git\n",
      "2025-06-04 19:04:35,701 - WARNING - nuevo.py:1017 - No se pudo obtener el git hash: Command '['git', 'rev-parse', 'HEAD']' returned non-zero exit status 128.\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1021 - --- Configuración de la Ejecución ---\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - batch_size: 32\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - beta_vae: 1.0\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - channels_to_use: ['1', '2', '3']\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - classifier_stratify_cols: ['Sex', 'Site']\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - classifier_type: svm\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - classifier_use_class_weight: True\n",
      "2025-06-04 19:04:35,701 - INFO - nuevo.py:1023 - cyclical_beta_n_cycles: 4\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - cyclical_beta_ratio_increase: 0.5\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - dropout_rate_vae: 0.15\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - early_stopping_patience_vae: 25\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - epochs_vae: 450\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - git_hash: N/A\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - global_tensor_path: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - gridsearch_scoring: balanced_accuracy\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - inner_folds: 3\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - intermediate_fc_dim_vae: 4624\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - latent_dim: 512\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - log_interval_epochs_vae: 10\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - lr_scheduler_patience_vae: 15\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - lr_vae: 0.0001\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - metadata_path: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - mlp_classifier_hidden_layers: 100\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - norm_mode: zscore_offdiag\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - num_workers: 4\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - outer_folds: 5\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - output_dir: resultados/v1.4\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - repeated_outer_folds_n_repeats: 1\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - seed: 42\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - use_layernorm_vae_fc: True\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - vae_final_activation: tanh\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - vae_val_split_ratio: 0.15\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1023 - weight_decay_vae: 1e-05\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:1024 - ------------------------------------\n",
      "2025-06-04 19:04:35,702 - INFO - nuevo.py:350 - Cargando tensor global desde: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 19:04:36,179 - INFO - nuevo.py:358 - Tensor global cargado. Forma: (431, 6, 131, 131)\n",
      "2025-06-04 19:04:36,179 - INFO - nuevo.py:366 - Cargando metadatos desde: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 19:04:36,183 - INFO - nuevo.py:373 - Metadatos cargados. Forma: (434, 24)\n",
      "2025-06-04 19:04:36,185 - INFO - nuevo.py:563 - Usando canales seleccionados (índices en tensor original): [1, 2, 3]\n",
      "2025-06-04 19:04:36,185 - INFO - nuevo.py:564 - Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'MI_KNN_Symmetric', 'dFC_AbsDiffMean']\n",
      "2025-06-04 19:04:36,199 - WARNING - nuevo.py:605 - Columna de estratificación 'Site' no encontrada en metadatos. Se ignorará.\n",
      "2025-06-04 19:04:36,204 - INFO - nuevo.py:609 - Estratificando folds del clasificador por: ['ResearchGroup', 'Sex']\n",
      "2025-06-04 19:04:36,204 - INFO - nuevo.py:618 - Iniciando clasificación CN vs AD. Total sujetos CN/AD disponibles en metadatos y tensor: 184. CN: 89, AD: 95\n",
      "2025-06-04 19:04:36,204 - INFO - nuevo.py:631 - Usando StratifiedKFold con 5 splits.\n",
      "2025-06-04 19:04:36,205 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 1/5 ---\n",
      "2025-06-04 19:04:36,216 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 19:04:36,216 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 19:04:36,216 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 19:04:36,289 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.046, std=0.770)\n",
      "2025-06-04 19:04:36,349 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.812)\n",
      "2025-06-04 19:04:36,405 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.769)\n",
      "2025-06-04 19:04:36,421 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 19:04:36,447 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 19:04:36,447 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 19:04:36,844 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:04:36,844 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 4624.\n",
      "2025-06-04 19:04:36,844 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 2312 (current is 512).\n",
      "2025-06-04 19:04:36,882 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:04:37,260 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 19:04:37,260 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 19:04:37,874 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 19:04:37,874 - INFO - nuevo.py:716 - Entrenando VAE para el fold 1...\n",
      "2025-06-04 19:04:48,691 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 10/450, Train Loss: 45944.9625, Beta: 0.1600, LR: 1.00e-04, Val Loss: 44684.1578\n",
      "2025-06-04 19:04:59,108 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 20/450, Train Loss: 39170.0843, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38553.2021\n",
      "2025-06-04 19:05:09,381 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 30/450, Train Loss: 36080.5404, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35926.3141\n",
      "2025-06-04 19:05:19,723 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 40/450, Train Loss: 34139.5719, Beta: 0.6933, LR: 1.00e-04, Val Loss: 34248.2857\n",
      "2025-06-04 19:05:30,106 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 50/450, Train Loss: 32639.1490, Beta: 0.8711, LR: 1.00e-04, Val Loss: 33327.5818\n",
      "2025-06-04 19:05:40,396 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 60/450, Train Loss: 31356.0911, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32664.5318\n",
      "2025-06-04 19:05:50,746 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 70/450, Train Loss: 30342.2855, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32216.5898\n",
      "2025-06-04 19:06:01,068 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 80/450, Train Loss: 29528.0198, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31744.0020\n",
      "2025-06-04 19:06:11,460 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 90/450, Train Loss: 28706.1485, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31442.5849\n",
      "2025-06-04 19:06:21,940 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 100/450, Train Loss: 28028.6509, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31207.7007\n",
      "2025-06-04 19:06:32,288 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 110/450, Train Loss: 27471.8372, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30951.1336\n",
      "2025-06-04 19:06:42,662 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 120/450, Train Loss: 26430.1121, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30552.3659\n",
      "2025-06-04 19:06:52,866 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 130/450, Train Loss: 26006.2650, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30140.4012\n",
      "2025-06-04 19:07:03,149 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 140/450, Train Loss: 25754.3041, Beta: 0.4711, LR: 1.00e-04, Val Loss: 30298.4620\n",
      "2025-06-04 19:07:13,278 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 150/450, Train Loss: 25496.1647, Beta: 0.6489, LR: 1.00e-05, Val Loss: 30184.8665\n",
      "2025-06-04 19:07:23,423 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 160/450, Train Loss: 25406.6837, Beta: 0.8267, LR: 1.00e-05, Val Loss: 30215.4964\n",
      "2025-06-04 19:07:33,533 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 170/450, Train Loss: 25673.8477, Beta: 1.0000, LR: 1.00e-05, Val Loss: 30323.7927\n",
      "2025-06-04 19:07:43,660 - INFO - nuevo.py:773 - Fold 1, VAE Epoch 180/450, Train Loss: 25512.3322, Beta: 1.0000, LR: 1.00e-06, Val Loss: 30242.0400\n",
      "2025-06-04 19:07:46,850 - INFO - nuevo.py:769 - Fold 1: Early stopping VAE en epoch 183. Mejor val_loss: 30123.1635\n",
      "2025-06-04 19:07:46,850 - INFO - nuevo.py:776 - Fold 1: Cargando mejor modelo VAE con val_loss: 30123.1635\n",
      "2025-06-04 19:07:49,794 - INFO - nuevo.py:786 - Modelo VAE del fold 1 guardado en: resultados/v1.4/vae_fold_1_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 19:07:49,800 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 19:07:49,835 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 19:07:49,867 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 1 (scoring: balanced_accuracy)...\n",
      "2025-06-04 19:07:50,636 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 1: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 19:07:50,643 - INFO - nuevo.py:864 - Fold 1 - Resultados Clasificador (svm):\n",
      "2025-06-04 19:07:50,643 - INFO - nuevo.py:865 -   AUC: 0.9152, PR-AUC: 0.9437, Acc: 0.8378, Bal. Acc: 0.8421\n",
      "2025-06-04 19:07:50,643 - INFO - nuevo.py:866 -   Sens (AD): 0.6842, Spec (CN): 1.0000, F1 (AD): 0.8125\n",
      "2025-06-04 19:07:50,644 - INFO - nuevo.py:873 -   Fold 1 Train (Clf) IDs Hash: 33237429bb1ab7b98399c8fee1fd0bd3\n",
      "2025-06-04 19:07:50,644 - INFO - nuevo.py:874 -   Fold 1 Test (Clf) IDs Hash: 150c24ef7d8b9da74a4d204897a8df53\n",
      "2025-06-04 19:07:50,744 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 2/5 ---\n",
      "2025-06-04 19:07:50,757 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 19:07:50,757 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 19:07:50,757 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 19:07:50,828 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.050, std=0.778)\n",
      "2025-06-04 19:07:50,884 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.056, std=0.816)\n",
      "2025-06-04 19:07:50,939 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.037, std=0.769)\n",
      "2025-06-04 19:07:50,954 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 19:07:50,957 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 19:07:50,957 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 19:07:51,340 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:07:51,341 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 4624.\n",
      "2025-06-04 19:07:51,341 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 2312 (current is 512).\n",
      "2025-06-04 19:07:51,369 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:07:51,738 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 19:07:51,739 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 19:07:51,848 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 19:07:51,848 - INFO - nuevo.py:716 - Entrenando VAE para el fold 2...\n",
      "2025-06-04 19:08:02,172 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 10/450, Train Loss: 46178.3316, Beta: 0.1600, LR: 1.00e-04, Val Loss: 43052.2151\n",
      "2025-06-04 19:08:12,325 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 20/450, Train Loss: 39449.8765, Beta: 0.3378, LR: 1.00e-04, Val Loss: 36756.1859\n",
      "2025-06-04 19:08:22,452 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 30/450, Train Loss: 36005.8984, Beta: 0.5156, LR: 1.00e-04, Val Loss: 33972.7339\n",
      "2025-06-04 19:08:32,622 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 40/450, Train Loss: 33808.4938, Beta: 0.6933, LR: 1.00e-04, Val Loss: 32658.0130\n",
      "2025-06-04 19:08:42,983 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 50/450, Train Loss: 32439.4872, Beta: 0.8711, LR: 1.00e-04, Val Loss: 31703.5549\n",
      "2025-06-04 19:08:53,261 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 60/450, Train Loss: 31203.9815, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31089.7148\n",
      "2025-06-04 19:09:03,563 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 70/450, Train Loss: 30272.0446, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30693.4005\n",
      "2025-06-04 19:09:13,608 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 80/450, Train Loss: 29286.9602, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30346.4868\n",
      "2025-06-04 19:09:23,788 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 90/450, Train Loss: 28628.7667, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30072.3792\n",
      "2025-06-04 19:09:34,018 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 100/450, Train Loss: 27840.7094, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29882.0004\n",
      "2025-06-04 19:09:44,131 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 110/450, Train Loss: 27385.6226, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29770.9318\n",
      "2025-06-04 19:09:54,255 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 120/450, Train Loss: 26340.0460, Beta: 0.1156, LR: 1.00e-04, Val Loss: 29178.4712\n",
      "2025-06-04 19:10:04,458 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 130/450, Train Loss: 25980.6836, Beta: 0.2933, LR: 1.00e-04, Val Loss: 28957.3853\n",
      "2025-06-04 19:10:14,622 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 140/450, Train Loss: 25713.0380, Beta: 0.4711, LR: 1.00e-04, Val Loss: 28831.2018\n",
      "2025-06-04 19:10:24,752 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 150/450, Train Loss: 25445.2422, Beta: 0.6489, LR: 1.00e-04, Val Loss: 28915.3803\n",
      "2025-06-04 19:10:34,910 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 160/450, Train Loss: 25152.3032, Beta: 0.8267, LR: 1.00e-04, Val Loss: 28680.3922\n",
      "2025-06-04 19:10:45,131 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 170/450, Train Loss: 25094.4717, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28751.2323\n",
      "2025-06-04 19:10:55,330 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 180/450, Train Loss: 24702.2511, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28715.3836\n",
      "2025-06-04 19:11:05,429 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 190/450, Train Loss: 24254.3478, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28495.6285\n",
      "2025-06-04 19:11:15,591 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 200/450, Train Loss: 24205.3901, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28358.6637\n",
      "2025-06-04 19:11:25,770 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 210/450, Train Loss: 23852.2922, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28291.0891\n",
      "2025-06-04 19:11:35,952 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 220/450, Train Loss: 23557.6533, Beta: 1.0000, LR: 1.00e-04, Val Loss: 28199.6591\n",
      "2025-06-04 19:11:46,201 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 230/450, Train Loss: 22609.4712, Beta: 0.0711, LR: 1.00e-04, Val Loss: 27584.8931\n",
      "2025-06-04 19:11:56,356 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 240/450, Train Loss: 22442.3681, Beta: 0.2489, LR: 1.00e-04, Val Loss: 27578.5732\n",
      "2025-06-04 19:12:07,081 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 250/450, Train Loss: 22486.8293, Beta: 0.4267, LR: 1.00e-04, Val Loss: 27562.2730\n",
      "2025-06-04 19:12:17,212 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 260/450, Train Loss: 22273.5554, Beta: 0.6044, LR: 1.00e-04, Val Loss: 27684.5022\n",
      "2025-06-04 19:12:27,357 - INFO - nuevo.py:773 - Fold 2, VAE Epoch 270/450, Train Loss: 22249.8026, Beta: 0.7822, LR: 1.00e-05, Val Loss: 27600.0285\n",
      "2025-06-04 19:12:31,402 - INFO - nuevo.py:769 - Fold 2: Early stopping VAE en epoch 274. Mejor val_loss: 27514.2089\n",
      "2025-06-04 19:12:31,402 - INFO - nuevo.py:776 - Fold 2: Cargando mejor modelo VAE con val_loss: 27514.2089\n",
      "2025-06-04 19:12:34,301 - INFO - nuevo.py:786 - Modelo VAE del fold 2 guardado en: resultados/v1.4/vae_fold_2_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 19:12:34,310 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 19:12:34,349 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 19:12:34,382 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 2 (scoring: balanced_accuracy)...\n",
      "2025-06-04 19:12:34,648 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 2: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 19:12:34,654 - INFO - nuevo.py:864 - Fold 2 - Resultados Clasificador (svm):\n",
      "2025-06-04 19:12:34,654 - INFO - nuevo.py:865 -   AUC: 0.7807, PR-AUC: 0.8440, Acc: 0.6216, Bal. Acc: 0.6199\n",
      "2025-06-04 19:12:34,654 - INFO - nuevo.py:866 -   Sens (AD): 0.6842, Spec (CN): 0.5556, F1 (AD): 0.6500\n",
      "2025-06-04 19:12:34,654 - INFO - nuevo.py:873 -   Fold 2 Train (Clf) IDs Hash: 34e03b78fb1b8629fe0238d65a5035b6\n",
      "2025-06-04 19:12:34,654 - INFO - nuevo.py:874 -   Fold 2 Test (Clf) IDs Hash: 120bcd18354da654194d0a44983824f6\n",
      "2025-06-04 19:12:34,765 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 3/5 ---\n",
      "2025-06-04 19:12:34,779 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 19:12:34,779 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 19:12:34,779 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 19:12:35,020 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.775)\n",
      "2025-06-04 19:12:35,090 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.812)\n",
      "2025-06-04 19:12:35,146 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.766)\n",
      "2025-06-04 19:12:35,162 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 19:12:35,165 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 19:12:35,165 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 19:12:35,555 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:12:35,555 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 4624.\n",
      "2025-06-04 19:12:35,555 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 2312 (current is 512).\n",
      "2025-06-04 19:12:35,584 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:12:35,977 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 19:12:35,978 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 19:12:36,093 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 19:12:36,093 - INFO - nuevo.py:716 - Entrenando VAE para el fold 3...\n",
      "2025-06-04 19:12:46,654 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 10/450, Train Loss: 46387.9826, Beta: 0.1600, LR: 1.00e-04, Val Loss: 45037.1422\n",
      "2025-06-04 19:12:56,958 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 20/450, Train Loss: 39771.4541, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38527.2547\n",
      "2025-06-04 19:13:07,348 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 30/450, Train Loss: 36234.9668, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35739.2000\n",
      "2025-06-04 19:13:17,787 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 40/450, Train Loss: 33910.0416, Beta: 0.6933, LR: 1.00e-04, Val Loss: 34047.6091\n",
      "2025-06-04 19:13:28,371 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 50/450, Train Loss: 32414.0158, Beta: 0.8711, LR: 1.00e-04, Val Loss: 33163.5573\n",
      "2025-06-04 19:13:39,031 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 60/450, Train Loss: 31249.6687, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32629.2198\n",
      "2025-06-04 19:13:49,220 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 70/450, Train Loss: 30357.2569, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32010.8529\n",
      "2025-06-04 19:13:59,827 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 80/450, Train Loss: 29414.9162, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31616.8734\n",
      "2025-06-04 19:14:10,309 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 90/450, Train Loss: 28446.2138, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31377.7878\n",
      "2025-06-04 19:14:20,586 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 100/450, Train Loss: 27829.9884, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31118.8876\n",
      "2025-06-04 19:14:31,276 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 110/450, Train Loss: 27203.3220, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31011.1957\n",
      "2025-06-04 19:14:41,947 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 120/450, Train Loss: 26289.6343, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30460.4634\n",
      "2025-06-04 19:14:52,348 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 130/450, Train Loss: 25913.1936, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30434.3477\n",
      "2025-06-04 19:15:02,603 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 140/450, Train Loss: 25584.2350, Beta: 0.4711, LR: 1.00e-04, Val Loss: 30438.1186\n",
      "2025-06-04 19:15:12,707 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 150/450, Train Loss: 25465.4926, Beta: 0.6489, LR: 1.00e-04, Val Loss: 30356.1193\n",
      "2025-06-04 19:15:22,879 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 160/450, Train Loss: 25264.6018, Beta: 0.8267, LR: 1.00e-04, Val Loss: 30347.3520\n",
      "2025-06-04 19:15:33,105 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 170/450, Train Loss: 24836.3971, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30099.0980\n",
      "2025-06-04 19:15:43,301 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 180/450, Train Loss: 24598.8179, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29978.1289\n",
      "2025-06-04 19:15:53,419 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 190/450, Train Loss: 24277.9735, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30129.1039\n",
      "2025-06-04 19:16:03,570 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 200/450, Train Loss: 24037.3109, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29827.7154\n",
      "2025-06-04 19:16:13,735 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 210/450, Train Loss: 23831.8728, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29818.1939\n",
      "2025-06-04 19:16:23,968 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 220/450, Train Loss: 23468.0895, Beta: 1.0000, LR: 1.00e-04, Val Loss: 29635.1849\n",
      "2025-06-04 19:16:34,079 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 230/450, Train Loss: 22529.5867, Beta: 0.0711, LR: 1.00e-04, Val Loss: 29087.1449\n",
      "2025-06-04 19:16:44,434 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 240/450, Train Loss: 22373.7732, Beta: 0.2489, LR: 1.00e-04, Val Loss: 28965.2759\n",
      "2025-06-04 19:16:54,978 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 250/450, Train Loss: 22309.5873, Beta: 0.4267, LR: 1.00e-04, Val Loss: 29031.3650\n",
      "2025-06-04 19:17:05,488 - INFO - nuevo.py:773 - Fold 3, VAE Epoch 260/450, Train Loss: 22227.2424, Beta: 0.6044, LR: 1.00e-04, Val Loss: 29008.7928\n",
      "2025-06-04 19:17:15,053 - INFO - nuevo.py:769 - Fold 3: Early stopping VAE en epoch 269. Mejor val_loss: 28917.5156\n",
      "2025-06-04 19:17:15,053 - INFO - nuevo.py:776 - Fold 3: Cargando mejor modelo VAE con val_loss: 28917.5156\n",
      "2025-06-04 19:17:17,863 - INFO - nuevo.py:786 - Modelo VAE del fold 3 guardado en: resultados/v1.4/vae_fold_3_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 19:17:17,875 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 19:17:17,906 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 19:17:17,938 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 3 (scoring: balanced_accuracy)...\n",
      "2025-06-04 19:17:18,196 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 3: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 19:17:18,202 - INFO - nuevo.py:864 - Fold 3 - Resultados Clasificador (svm):\n",
      "2025-06-04 19:17:18,203 - INFO - nuevo.py:865 -   AUC: 0.8304, PR-AUC: 0.8037, Acc: 0.8108, Bal. Acc: 0.8114\n",
      "2025-06-04 19:17:18,203 - INFO - nuevo.py:866 -   Sens (AD): 0.7895, Spec (CN): 0.8333, F1 (AD): 0.8108\n",
      "2025-06-04 19:17:18,203 - INFO - nuevo.py:873 -   Fold 3 Train (Clf) IDs Hash: 880f3db2b89bbbc3479891e1acf54160\n",
      "2025-06-04 19:17:18,204 - INFO - nuevo.py:874 -   Fold 3 Test (Clf) IDs Hash: cd438041de3b53fc761ec2dbc9f84012\n",
      "2025-06-04 19:17:18,327 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 4/5 ---\n",
      "2025-06-04 19:17:18,341 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 19:17:18,341 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 19:17:18,341 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 334 sujetos de entrenamiento.\n",
      "2025-06-04 19:17:18,459 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.777)\n",
      "2025-06-04 19:17:18,514 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.055, std=0.812)\n",
      "2025-06-04 19:17:18,573 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.037, std=0.768)\n",
      "2025-06-04 19:17:18,588 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 19:17:18,591 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 19:17:18,591 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 19:17:18,979 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:17:18,979 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 4624.\n",
      "2025-06-04 19:17:18,979 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 2312 (current is 512).\n",
      "2025-06-04 19:17:19,003 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:17:19,377 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 19:17:19,378 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 19:17:19,495 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 19:17:19,495 - INFO - nuevo.py:716 - Entrenando VAE para el fold 4...\n",
      "2025-06-04 19:17:30,232 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 10/450, Train Loss: 46292.6364, Beta: 0.1600, LR: 1.00e-04, Val Loss: 44089.5211\n",
      "2025-06-04 19:17:40,531 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 20/450, Train Loss: 39819.6743, Beta: 0.3378, LR: 1.00e-04, Val Loss: 38257.6495\n",
      "2025-06-04 19:17:50,678 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 30/450, Train Loss: 36162.7274, Beta: 0.5156, LR: 1.00e-04, Val Loss: 35389.0159\n",
      "2025-06-04 19:18:00,885 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 40/450, Train Loss: 34212.0634, Beta: 0.6933, LR: 1.00e-04, Val Loss: 33784.0549\n",
      "2025-06-04 19:18:11,056 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 50/450, Train Loss: 32669.1109, Beta: 0.8711, LR: 1.00e-04, Val Loss: 32991.7057\n",
      "2025-06-04 19:18:21,208 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 60/450, Train Loss: 31379.7238, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32457.7896\n",
      "2025-06-04 19:18:31,326 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 70/450, Train Loss: 30235.3285, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31872.0424\n",
      "2025-06-04 19:18:41,707 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 80/450, Train Loss: 29382.2701, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31449.0017\n",
      "2025-06-04 19:18:52,181 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 90/450, Train Loss: 28559.7165, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31247.6331\n",
      "2025-06-04 19:19:02,311 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 100/450, Train Loss: 28005.6431, Beta: 1.0000, LR: 1.00e-04, Val Loss: 31067.0693\n",
      "2025-06-04 19:19:12,625 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 110/450, Train Loss: 27280.7423, Beta: 1.0000, LR: 1.00e-04, Val Loss: 30807.0892\n",
      "2025-06-04 19:19:22,934 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 120/450, Train Loss: 26212.4543, Beta: 0.1156, LR: 1.00e-04, Val Loss: 30129.8322\n",
      "2025-06-04 19:19:33,594 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 130/450, Train Loss: 25767.0129, Beta: 0.2933, LR: 1.00e-04, Val Loss: 30102.1171\n",
      "2025-06-04 19:19:44,110 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 140/450, Train Loss: 25547.4736, Beta: 0.4711, LR: 1.00e-04, Val Loss: 30121.1195\n",
      "2025-06-04 19:19:54,755 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 150/450, Train Loss: 25293.0800, Beta: 0.6489, LR: 1.00e-04, Val Loss: 30047.6698\n",
      "2025-06-04 19:20:05,106 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 160/450, Train Loss: 25209.4974, Beta: 0.8267, LR: 1.00e-04, Val Loss: 30159.0419\n",
      "2025-06-04 19:20:15,363 - INFO - nuevo.py:773 - Fold 4, VAE Epoch 170/450, Train Loss: 25070.8954, Beta: 1.0000, LR: 1.00e-05, Val Loss: 30077.7243\n",
      "2025-06-04 19:20:19,437 - INFO - nuevo.py:769 - Fold 4: Early stopping VAE en epoch 174. Mejor val_loss: 29982.1866\n",
      "2025-06-04 19:20:19,437 - INFO - nuevo.py:776 - Fold 4: Cargando mejor modelo VAE con val_loss: 29982.1866\n",
      "2025-06-04 19:20:22,588 - INFO - nuevo.py:786 - Modelo VAE del fold 4 guardado en: resultados/v1.4/vae_fold_4_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 19:20:22,595 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (147 sujetos, 3 canales).\n",
      "2025-06-04 19:20:22,632 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (37 sujetos, 3 canales).\n",
      "2025-06-04 19:20:22,670 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 4 (scoring: balanced_accuracy)...\n",
      "2025-06-04 19:20:22,954 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 4: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 19:20:22,960 - INFO - nuevo.py:864 - Fold 4 - Resultados Clasificador (svm):\n",
      "2025-06-04 19:20:22,960 - INFO - nuevo.py:865 -   AUC: 0.7982, PR-AUC: 0.8344, Acc: 0.7297, Bal. Acc: 0.7281\n",
      "2025-06-04 19:20:22,960 - INFO - nuevo.py:866 -   Sens (AD): 0.7895, Spec (CN): 0.6667, F1 (AD): 0.7500\n",
      "2025-06-04 19:20:22,960 - INFO - nuevo.py:873 -   Fold 4 Train (Clf) IDs Hash: c22989182ae2a35200820690ad2375a3\n",
      "2025-06-04 19:20:22,960 - INFO - nuevo.py:874 -   Fold 4 Test (Clf) IDs Hash: 0217f63103cf5c7c039482f935f0ca07\n",
      "2025-06-04 19:20:23,061 - INFO - nuevo.py:637 - --- Iniciando Fold Externo 5/5 ---\n",
      "2025-06-04 19:20:23,075 - INFO - nuevo.py:679 - Normalizando datos para VAE...\n",
      "2025-06-04 19:20:23,076 - INFO - nuevo.py:411 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados.\n",
      "2025-06-04 19:20:23,076 - INFO - nuevo.py:412 - Parámetros de normalización se calcularán usando 335 sujetos de entrenamiento.\n",
      "2025-06-04 19:20:23,178 - INFO - nuevo.py:473 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.777)\n",
      "2025-06-04 19:20:23,251 - INFO - nuevo.py:473 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.056, std=0.812)\n",
      "2025-06-04 19:20:23,324 - INFO - nuevo.py:473 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.764)\n",
      "2025-06-04 19:20:23,339 - INFO - nuevo.py:696 - Usando dispositivo: cuda\n",
      "2025-06-04 19:20:23,341 - INFO - nuevo.py:123 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 19:20:23,341 - INFO - nuevo.py:124 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 19:20:23,730 - INFO - nuevo.py:148 - VAE: Intermediate FC dim (encoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:20:23,730 - INFO - nuevo.py:154 - VAE: Input dimension to fc_mu/fc_logvar: 4624.\n",
      "2025-06-04 19:20:23,730 - INFO - nuevo.py:156 - VAE: Based on this, a suggested latent_dim could be: 2312 (current is 512).\n",
      "2025-06-04 19:20:23,759 - INFO - nuevo.py:175 - VAE: Intermediate FC dim (decoder): 4624. Using LayerNorm: True\n",
      "2025-06-04 19:20:24,140 - INFO - nuevo.py:231 - Using fixed output_paddings for image_size=131: [0, 1, 0]\n",
      "2025-06-04 19:20:24,141 - INFO - nuevo.py:258 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 19:20:24,258 - INFO - nuevo.py:714 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 19:20:24,258 - INFO - nuevo.py:716 - Entrenando VAE para el fold 5...\n",
      "2025-06-04 19:20:34,489 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 10/450, Train Loss: 46448.7131, Beta: 0.1600, LR: 1.00e-04, Val Loss: 46468.4414\n",
      "2025-06-04 19:20:44,835 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 20/450, Train Loss: 39832.1549, Beta: 0.3378, LR: 1.00e-04, Val Loss: 39872.9138\n",
      "2025-06-04 19:20:55,291 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 30/450, Train Loss: 36158.4015, Beta: 0.5156, LR: 1.00e-04, Val Loss: 37065.6776\n",
      "2025-06-04 19:21:05,896 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 40/450, Train Loss: 34346.0866, Beta: 0.6933, LR: 1.00e-04, Val Loss: 35665.1464\n",
      "2025-06-04 19:21:16,444 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 50/450, Train Loss: 32560.9543, Beta: 0.8711, LR: 1.00e-04, Val Loss: 34514.5971\n",
      "2025-06-04 19:21:26,928 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 60/450, Train Loss: 31473.3747, Beta: 1.0000, LR: 1.00e-04, Val Loss: 33881.2552\n",
      "2025-06-04 19:21:37,793 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 70/450, Train Loss: 30334.0573, Beta: 1.0000, LR: 1.00e-04, Val Loss: 33531.9745\n",
      "2025-06-04 19:21:48,496 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 80/450, Train Loss: 29417.5204, Beta: 1.0000, LR: 1.00e-04, Val Loss: 33058.7018\n",
      "2025-06-04 19:21:59,113 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 90/450, Train Loss: 28684.7631, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32779.3823\n",
      "2025-06-04 19:22:09,906 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 100/450, Train Loss: 28102.8102, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32553.9137\n",
      "2025-06-04 19:22:20,356 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 110/450, Train Loss: 27390.9921, Beta: 1.0000, LR: 1.00e-04, Val Loss: 32387.6352\n",
      "2025-06-04 19:22:30,579 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 120/450, Train Loss: 26297.5564, Beta: 0.1156, LR: 1.00e-04, Val Loss: 31689.0132\n",
      "2025-06-04 19:22:41,010 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 130/450, Train Loss: 26013.8582, Beta: 0.2933, LR: 1.00e-04, Val Loss: 31747.7194\n",
      "2025-06-04 19:22:51,678 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 140/450, Train Loss: 25918.1635, Beta: 0.4711, LR: 1.00e-04, Val Loss: 31551.3561\n",
      "2025-06-04 19:23:02,295 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 150/450, Train Loss: 25681.2231, Beta: 0.6489, LR: 1.00e-04, Val Loss: 31705.1801\n",
      "2025-06-04 19:23:12,559 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 160/450, Train Loss: 25277.7279, Beta: 0.8267, LR: 1.00e-04, Val Loss: 31523.4089\n",
      "2025-06-04 19:23:22,984 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 170/450, Train Loss: 25031.2476, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31473.9342\n",
      "2025-06-04 19:23:33,454 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 180/450, Train Loss: 25065.5459, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31502.2659\n",
      "2025-06-04 19:23:43,767 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 190/450, Train Loss: 24927.0173, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31418.1339\n",
      "2025-06-04 19:23:54,020 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 200/450, Train Loss: 24866.7944, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31441.1482\n",
      "2025-06-04 19:24:04,695 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 210/450, Train Loss: 24942.5012, Beta: 1.0000, LR: 1.00e-05, Val Loss: 31435.0297\n",
      "2025-06-04 19:24:15,157 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 220/450, Train Loss: 24742.7660, Beta: 1.0000, LR: 1.00e-06, Val Loss: 31433.7534\n",
      "2025-06-04 19:24:25,639 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 230/450, Train Loss: 24058.0860, Beta: 0.0711, LR: 1.00e-06, Val Loss: 31017.6559\n",
      "2025-06-04 19:24:35,773 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 240/450, Train Loss: 24289.5703, Beta: 0.2489, LR: 1.00e-06, Val Loss: 31063.8533\n",
      "2025-06-04 19:24:46,456 - INFO - nuevo.py:773 - Fold 5, VAE Epoch 250/450, Train Loss: 24396.2823, Beta: 0.4267, LR: 1.00e-07, Val Loss: 31126.7492\n",
      "2025-06-04 19:24:48,499 - INFO - nuevo.py:769 - Fold 5: Early stopping VAE en epoch 252. Mejor val_loss: 30968.7155\n",
      "2025-06-04 19:24:48,499 - INFO - nuevo.py:776 - Fold 5: Cargando mejor modelo VAE con val_loss: 30968.7155\n",
      "2025-06-04 19:24:51,385 - INFO - nuevo.py:786 - Modelo VAE del fold 5 guardado en: resultados/v1.4/vae_fold_5_ld512_beta1.0_ch3_zscore_offdiag.pt\n",
      "2025-06-04 19:24:51,391 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (148 sujetos, 3 canales).\n",
      "2025-06-04 19:24:51,427 - INFO - nuevo.py:482 - Aplicando parámetros de normalización precalculados a subconjunto de datos (36 sujetos, 3 canales).\n",
      "2025-06-04 19:24:51,464 - INFO - nuevo.py:848 - Entrenando clasificador svm para el fold 5 (scoring: balanced_accuracy)...\n",
      "2025-06-04 19:24:51,818 - INFO - nuevo.py:850 - Mejores hiperparámetros svm para fold 5: {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}\n",
      "2025-06-04 19:24:51,823 - INFO - nuevo.py:864 - Fold 5 - Resultados Clasificador (svm):\n",
      "2025-06-04 19:24:51,823 - INFO - nuevo.py:865 -   AUC: 0.6842, PR-AUC: 0.6772, Acc: 0.6667, Bal. Acc: 0.6749\n",
      "2025-06-04 19:24:51,823 - INFO - nuevo.py:866 -   Sens (AD): 0.5263, Spec (CN): 0.8235, F1 (AD): 0.6250\n",
      "2025-06-04 19:24:51,824 - INFO - nuevo.py:873 -   Fold 5 Train (Clf) IDs Hash: 1ad182a139a4bab496c7cb46246faa69\n",
      "2025-06-04 19:24:51,824 - INFO - nuevo.py:874 -   Fold 5 Test (Clf) IDs Hash: c75bad004aa9a6304767ba0f099959b9\n",
      "2025-06-04 19:24:51,933 - INFO - nuevo.py:890 - \n",
      "--- Resumen de Rendimiento (Promedio sobre Folds Externos) ---\n",
      "2025-06-04 19:24:51,933 - INFO - nuevo.py:895 - Auc                 : 0.8018 +/- 0.0836\n",
      "2025-06-04 19:24:51,933 - INFO - nuevo.py:895 - Pr_auc              : 0.8206 +/- 0.0958\n",
      "2025-06-04 19:24:51,933 - INFO - nuevo.py:895 - Accuracy            : 0.7333 +/- 0.0920\n",
      "2025-06-04 19:24:51,934 - INFO - nuevo.py:895 - Balanced_accuracy   : 0.7353 +/- 0.0925\n",
      "2025-06-04 19:24:51,934 - INFO - nuevo.py:895 - Sensitivity         : 0.6947 +/- 0.1079\n",
      "2025-06-04 19:24:51,934 - INFO - nuevo.py:895 - Specificity         : 0.7758 +/- 0.1705\n",
      "2025-06-04 19:24:51,934 - INFO - nuevo.py:895 - F1_score            : 0.7297 +/- 0.0883\n",
      "2025-06-04 19:24:51,936 - INFO - nuevo.py:916 - Resultados de clasificación guardados en: resultados/v1.4/clf_results_svm_vae_zscore_offdiag_ld512_beta1.0_cycBeta4_ch3sel_intFC4624_dropVAE0.15_lnFCTrue_esVAE25_outer5x1_scorebalanced_accuracy.csv\n",
      "2025-06-04 19:24:51,945 - INFO - nuevo.py:925 - Sumario estadístico de métricas guardado en: resultados/v1.4/summary_stats_clf_results_svm_vae_zscore_offdiag_ld512_beta1.0_cycBeta4_ch3sel_intFC4624_dropVAE0.15_lnFCTrue_esVAE25_outer5x1_scorebalanced_accuracy.txt\n",
      "2025-06-04 19:24:51,951 - INFO - nuevo.py:1034 - Pipeline completado.\n",
      "2025-06-04 19:24:51,951 - INFO - nuevo.py:1035 - --- Consideraciones sobre Normalización y Activación Final del VAE (Recordatorio) ---\n",
      "2025-06-04 19:24:51,951 - INFO - nuevo.py:1036 - Normalización: 'minmax_offdiag' -> [0,1] (ideal con sigmoid), 'zscore_offdiag' -> media 0, std 1 (mejor con tanh/linear).\n",
      "2025-06-04 19:24:51,951 - INFO - nuevo.py:1037 - Activación Final VAE: 'sigmoid' -> [0,1], 'tanh' -> [-1,1], 'linear' -> sin restricción.\n",
      "2025-06-04 19:24:51,951 - INFO - nuevo.py:1038 - Asegurar compatibilidad entre normalización y activación es clave.\n"
     ]
    }
   ],
   "source": [
    "!python nuevo.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path      /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv \\\n",
    "    --output_dir resultados/v1.4 \\\n",
    "    --channels_to_use 1 2 3 \\\n",
    "    --outer_folds 5 \\\n",
    "    --repeated_outer_folds_n_repeats 1 \\\n",
    "    --inner_folds 3 \\\n",
    "    --classifier_stratify_cols Sex Site \\\n",
    "    --latent_dim 512 \\\n",
    "    --lr_vae 1e-4 \\\n",
    "    --epochs_vae 450 \\\n",
    "    --batch_size 32 \\\n",
    "    --beta_vae 1.0 \\\n",
    "    --cyclical_beta_n_cycles 2 \\\n",
    "    --cyclical_beta_ratio_increase 0.5 \\\n",
    "    --weight_decay_vae 1e-5 \\\n",
    "    --vae_final_activation tanh \\\n",
    "    --intermediate_fc_dim_vae 4624 \\\n",
    "    --dropout_rate_vae 0.15 \\\n",
    "    --use_layernorm_vae_fc \\\n",
    "    --vae_val_split_ratio 0.15 \\\n",
    "    --early_stopping_patience_vae 25 \\\n",
    "    --lr_scheduler_patience_vae 15 \\\n",
    "    --classifier_type svm \\\n",
    "    --gridsearch_scoring balanced_accuracy \\\n",
    "    --classifier_use_class_weight \\\n",
    "    --norm_mode zscore_offdiag \\\n",
    "    --seed 42 \\\n",
    "    --num_workers 4 \\\n",
    "    --log_interval_epochs_vae 10"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
