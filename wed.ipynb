{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2719512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: no es un repositorio git (ni ninguno de los directorios superiores): .git\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1015 - Git commit hash: N/A\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1017 - --- Configuración de la Ejecución (v1.5.1) ---\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - batch_size: 32\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - beta_vae: 1.0\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - channels_to_use: ['1', '2', '3', '4']\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - classifier_hp_tune_ratio: 0.25\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - classifier_stratify_cols: ['Sex']\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - classifier_types: ['rf', 'gb']\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - classifier_use_class_weight: True\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - cyclical_beta_n_cycles: 5\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - cyclical_beta_ratio_increase: 0.5\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - decoder_type: upsample_conv\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - dropout_rate_vae: 0.3\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - early_stopping_patience_vae: 30\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - epochs_vae: 300\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - git_hash: N/A\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - global_tensor_path: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - gridsearch_scoring: balanced_accuracy\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - inner_folds: 5\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - intermediate_fc_dim_vae: quarter\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - latent_dim: 512\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - latent_features_type: mu\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - log_interval_epochs_vae: 5\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - lr_scheduler_patience_vae: 20\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - lr_vae: 0.0001\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - metadata_path: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - mlp_classifier_hidden_layers: 128,64\n",
      "2025-06-04 21:02:37,159 - INFO - wed.py:1019 - n_jobs_gridsearch: 4\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - norm_mode: zscore_offdiag\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - num_conv_layers_encoder: 4\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - num_workers: 4\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - outer_folds: 5\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - output_dir: ./resultados_tesis/experimento_multi\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - repeated_outer_folds_n_repeats: 2\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - save_fold_artefacts: True\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - save_vae_training_history: True\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - seed: 42\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - use_layernorm_vae_fc: True\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - vae_final_activation: tanh\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - vae_val_split_ratio: 0.2\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1019 - weight_decay_vae: 1e-05\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:1020 - ------------------------------------\n",
      "2025-06-04 21:02:37,160 - INFO - wed.py:351 - Cargando tensor global desde: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 21:02:37,676 - INFO - wed.py:359 - Tensor global cargado. Forma: (431, 6, 131, 131)\n",
      "2025-06-04 21:02:37,676 - INFO - wed.py:364 - Cargando metadatos desde: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 21:02:37,680 - INFO - wed.py:371 - Metadatos cargados. Forma: (434, 24)\n",
      "2025-06-04 21:02:37,701 - INFO - wed.py:525 - Usando canales seleccionados (índices): [1, 2, 3, 4]\n",
      "2025-06-04 21:02:37,701 - INFO - wed.py:526 - Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'MI_KNN_Symmetric', 'dFC_AbsDiffMean', 'dFC_StdDev']\n",
      "2025-06-04 21:02:37,707 - INFO - wed.py:554 - Estratificando folds del clasificador por: ['ResearchGroup', 'Sex']\n",
      "2025-06-04 21:02:37,707 - INFO - wed.py:559 - Sujetos CN/AD para clasificación: 184. CN: 89, AD: 95\n",
      "2025-06-04 21:02:37,707 - INFO - wed.py:567 - Usando CV externa: RepeatedStratifiedKFold con 10 iteraciones totales.\n",
      "2025-06-04 21:02:37,708 - INFO - wed.py:575 - --- Iniciando Fold Externo 1/10 ---\n",
      "2025-06-04 21:02:37,727 - INFO - wed.py:606 - Sujetos VAE actual train (del pool): 315, VAE internal val (del pool): 79\n",
      "2025-06-04 21:02:37,727 - INFO - wed.py:392 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 4 canales seleccionados.\n",
      "2025-06-04 21:02:37,727 - INFO - wed.py:393 - Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "2025-06-04 21:02:37,812 - INFO - wed.py:450 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.047, std=0.775)\n",
      "2025-06-04 21:02:37,875 - INFO - wed.py:450 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.057, std=0.815)\n",
      "2025-06-04 21:02:37,932 - INFO - wed.py:450 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.035, std=0.768)\n",
      "2025-06-04 21:02:37,997 - INFO - wed.py:450 - Canal 'dFC_StdDev': Off-diag zscore_offdiag (train_params: mean=0.037, std=0.716)\n",
      "2025-06-04 21:02:38,016 - INFO - wed.py:622 - Usando dispositivo: cuda\n",
      "2025-06-04 21:02:38,037 - INFO - wed.py:149 - VAE Encoder: Input Channels: 4, Num Conv Layers: 4\n",
      "2025-06-04 21:02:38,037 - INFO - wed.py:150 - VAE Encoder: Conv Channels: [16, 32, 64, 128]\n",
      "2025-06-04 21:02:38,037 - INFO - wed.py:151 - VAE Encoder: Kernels: [7, 5, 5, 3], Strides: [2, 2, 2, 2], Paddings: [1, 1, 1, 1]\n",
      "2025-06-04 21:02:38,037 - INFO - wed.py:152 - VAE Encoder: Spatial Dims (Input to Output): [131, 64, 31, 15, 8]\n",
      "2025-06-04 21:02:38,037 - INFO - wed.py:153 - VAE Encoder: Calculated flattened size after conv = 8192 (final conv output channels: 128, final spatial dim after encoder: 8)\n",
      "2025-06-04 21:02:38,123 - INFO - wed.py:187 - VAE: Intermediate FC dim (encoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:02:38,137 - INFO - wed.py:210 - VAE: Intermediate FC dim (decoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:02:38,216 - INFO - wed.py:219 - Using Upsample-Conv decoder.\n",
      "2025-06-04 21:02:38,218 - INFO - wed.py:290 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 21:02:38,786 - INFO - wed.py:640 - Entrenando VAE para el fold 1 (Decoder: upsample_conv, Encoder Layers: 4)...\n",
      "2025-06-04 21:02:42,456 - INFO - wed.py:695 - F1 VAE E5/300, TrL: 73783.8027, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 69552.6949\n",
      "2025-06-04 21:02:45,581 - INFO - wed.py:695 - F1 VAE E10/300, TrL: 70770.3347, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 67816.2544\n",
      "2025-06-04 21:02:48,767 - INFO - wed.py:695 - F1 VAE E15/300, TrL: 69013.0201, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 67290.8609\n",
      "2025-06-04 21:02:51,862 - INFO - wed.py:695 - F1 VAE E20/300, TrL: 68516.2452, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 66768.9330\n",
      "2025-06-04 21:02:54,903 - INFO - wed.py:695 - F1 VAE E25/300, TrL: 67936.5557, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 66133.9375\n",
      "2025-06-04 21:02:58,063 - INFO - wed.py:695 - F1 VAE E30/300, TrL: 67229.1137, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 65551.9876\n",
      "2025-06-04 21:03:01,184 - INFO - wed.py:695 - F1 VAE E35/300, TrL: 66637.3818, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 64913.1689\n",
      "2025-06-04 21:03:04,350 - INFO - wed.py:695 - F1 VAE E40/300, TrL: 66030.1749, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 64348.8375\n",
      "2025-06-04 21:03:07,509 - INFO - wed.py:695 - F1 VAE E45/300, TrL: 65560.5188, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 63698.2732\n",
      "2025-06-04 21:03:10,689 - INFO - wed.py:695 - F1 VAE E50/300, TrL: 64909.9934, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 63072.8024\n",
      "2025-06-04 21:03:13,815 - INFO - wed.py:695 - F1 VAE E55/300, TrL: 64409.9836, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 62465.2369\n",
      "2025-06-04 21:03:16,929 - INFO - wed.py:695 - F1 VAE E60/300, TrL: 64026.1702, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 61925.0190\n",
      "2025-06-04 21:03:20,113 - INFO - wed.py:695 - F1 VAE E65/300, TrL: 63281.3509, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 61158.3703\n",
      "2025-06-04 21:03:23,373 - INFO - wed.py:695 - F1 VAE E70/300, TrL: 62941.9146, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 60786.1455\n",
      "2025-06-04 21:03:26,630 - INFO - wed.py:695 - F1 VAE E75/300, TrL: 62526.1076, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 60329.2229\n",
      "2025-06-04 21:03:29,793 - INFO - wed.py:695 - F1 VAE E80/300, TrL: 62202.1056, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 59909.6818\n",
      "2025-06-04 21:03:32,953 - INFO - wed.py:695 - F1 VAE E85/300, TrL: 61887.0225, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 59529.6325\n",
      "2025-06-04 21:03:36,155 - INFO - wed.py:695 - F1 VAE E90/300, TrL: 61660.5150, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 59084.7980\n",
      "2025-06-04 21:03:39,307 - INFO - wed.py:695 - F1 VAE E95/300, TrL: 61345.3200, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 58756.0007\n",
      "2025-06-04 21:03:42,434 - INFO - wed.py:695 - F1 VAE E100/300, TrL: 61089.5347, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 58275.1423\n",
      "2025-06-04 21:03:45,619 - INFO - wed.py:695 - F1 VAE E105/300, TrL: 60534.1227, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 57997.6497\n",
      "2025-06-04 21:03:48,814 - INFO - wed.py:695 - F1 VAE E110/300, TrL: 60270.2782, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 57656.2952\n",
      "2025-06-04 21:03:52,051 - INFO - wed.py:695 - F1 VAE E115/300, TrL: 59872.7541, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 57402.7562\n",
      "2025-06-04 21:03:55,236 - INFO - wed.py:695 - F1 VAE E120/300, TrL: 59868.8717, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 57044.3761\n",
      "2025-06-04 21:03:58,464 - INFO - wed.py:695 - F1 VAE E125/300, TrL: 59294.0565, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 56711.3578\n",
      "2025-06-04 21:04:01,803 - INFO - wed.py:695 - F1 VAE E130/300, TrL: 59148.7531, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 56390.7027\n",
      "2025-06-04 21:04:05,059 - INFO - wed.py:695 - F1 VAE E135/300, TrL: 58994.3813, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 56203.1346\n",
      "2025-06-04 21:04:08,365 - INFO - wed.py:695 - F1 VAE E140/300, TrL: 58693.1183, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 56027.2743\n",
      "2025-06-04 21:04:11,624 - INFO - wed.py:695 - F1 VAE E145/300, TrL: 58612.6830, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 55845.0013\n",
      "2025-06-04 21:04:14,887 - INFO - wed.py:695 - F1 VAE E150/300, TrL: 58383.2873, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 55477.1096\n",
      "2025-06-04 21:04:18,096 - INFO - wed.py:695 - F1 VAE E155/300, TrL: 57995.4669, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 55313.9821\n",
      "2025-06-04 21:04:21,247 - INFO - wed.py:695 - F1 VAE E160/300, TrL: 57761.8583, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 55119.7839\n",
      "2025-06-04 21:04:24,512 - INFO - wed.py:695 - F1 VAE E165/300, TrL: 57579.6315, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54951.5788\n",
      "2025-06-04 21:04:27,769 - INFO - wed.py:695 - F1 VAE E170/300, TrL: 57323.4377, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54705.1161\n",
      "2025-06-04 21:04:31,010 - INFO - wed.py:695 - F1 VAE E175/300, TrL: 57288.6455, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54482.9903\n",
      "2025-06-04 21:04:34,367 - INFO - wed.py:695 - F1 VAE E180/300, TrL: 57028.0328, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54453.9996\n",
      "2025-06-04 21:04:37,658 - INFO - wed.py:695 - F1 VAE E185/300, TrL: 56620.8707, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 53992.4863\n",
      "2025-06-04 21:04:40,953 - INFO - wed.py:695 - F1 VAE E190/300, TrL: 56413.9170, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 53759.5363\n",
      "2025-06-04 21:04:44,217 - INFO - wed.py:695 - F1 VAE E195/300, TrL: 56271.5922, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 53727.8313\n",
      "2025-06-04 21:04:47,482 - INFO - wed.py:695 - F1 VAE E200/300, TrL: 56424.5781, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 53516.9969\n",
      "2025-06-04 21:04:50,715 - INFO - wed.py:695 - F1 VAE E205/300, TrL: 56270.0264, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 53563.9271\n",
      "2025-06-04 21:04:54,004 - INFO - wed.py:695 - F1 VAE E210/300, TrL: 56087.6639, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 53467.3650\n",
      "2025-06-04 21:04:57,278 - INFO - wed.py:695 - F1 VAE E215/300, TrL: 56062.1685, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 53242.7869\n",
      "2025-06-04 21:05:00,527 - INFO - wed.py:695 - F1 VAE E220/300, TrL: 55812.3034, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 53200.1941\n",
      "2025-06-04 21:05:03,839 - INFO - wed.py:695 - F1 VAE E225/300, TrL: 55766.7601, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 53039.2412\n",
      "2025-06-04 21:05:07,058 - INFO - wed.py:695 - F1 VAE E230/300, TrL: 55615.1771, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52929.6311\n",
      "2025-06-04 21:05:10,284 - INFO - wed.py:695 - F1 VAE E235/300, TrL: 55547.6338, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52867.8079\n",
      "2025-06-04 21:05:13,533 - INFO - wed.py:695 - F1 VAE E240/300, TrL: 55416.0446, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52770.0011\n",
      "2025-06-04 21:05:16,746 - INFO - wed.py:695 - F1 VAE E245/300, TrL: 54958.3233, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 52509.7279\n",
      "2025-06-04 21:05:19,904 - INFO - wed.py:695 - F1 VAE E250/300, TrL: 55059.7541, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 52444.4700\n",
      "2025-06-04 21:05:23,122 - INFO - wed.py:695 - F1 VAE E255/300, TrL: 54938.8825, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 52351.6137\n",
      "2025-06-04 21:05:26,400 - INFO - wed.py:695 - F1 VAE E260/300, TrL: 54961.6148, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 52489.1853\n",
      "2025-06-04 21:05:29,616 - INFO - wed.py:695 - F1 VAE E265/300, TrL: 54781.4879, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 52327.0345\n",
      "2025-06-04 21:05:32,870 - INFO - wed.py:695 - F1 VAE E270/300, TrL: 54809.9295, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 52341.7103\n",
      "2025-06-04 21:05:36,178 - INFO - wed.py:695 - F1 VAE E275/300, TrL: 54703.7257, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52284.0325\n",
      "2025-06-04 21:05:39,510 - INFO - wed.py:695 - F1 VAE E280/300, TrL: 54645.5262, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52212.0899\n",
      "2025-06-04 21:05:42,788 - INFO - wed.py:695 - F1 VAE E285/300, TrL: 54547.3957, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52044.7978\n",
      "2025-06-04 21:05:46,081 - INFO - wed.py:695 - F1 VAE E290/300, TrL: 54597.9287, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 52043.9644\n",
      "2025-06-04 21:05:49,342 - INFO - wed.py:695 - F1 VAE E295/300, TrL: 54333.7596, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 51944.6761\n",
      "2025-06-04 21:05:52,617 - INFO - wed.py:695 - F1 VAE E300/300, TrL: 54424.5152, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 51859.4873\n",
      "2025-06-04 21:05:52,618 - INFO - wed.py:700 - Fold 1: VAE final model loaded (best VAE val_loss: 51859.4873).\n",
      "2025-06-04 21:05:53,226 - INFO - wed.py:704 - Modelo VAE del fold 1 guardado en: resultados_tesis/experimento_multi/fold_1/vae_model_fold_1.pt\n",
      "2025-06-04 21:05:53,718 - INFO - wed.py:782 -   --- Entrenando Clasificador: rf ---\n",
      "2025-06-04 21:05:53,719 - INFO - wed.py:814 -     Ajustando hiperparámetros para rf en 37 muestras...\n",
      "2025-06-04 21:06:25,223 - INFO - wed.py:817 -     Mejores hiperparámetros para rf: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "2025-06-04 21:06:25,225 - INFO - wed.py:829 -     Entrenando rf final en 147 muestras...\n",
      "2025-06-04 21:06:25,298 - INFO - wed.py:858 -     Resultados Fold 1 (rf): AUC=0.8421, Bal.Acc=0.8114, F1=0.8108\n",
      "2025-06-04 21:06:25,309 - INFO - wed.py:863 -     Scaler latente y modelo rf del fold 1 guardados.\n",
      "2025-06-04 21:06:25,309 - INFO - wed.py:782 -   --- Entrenando Clasificador: gb ---\n",
      "2025-06-04 21:06:25,310 - INFO - wed.py:814 -     Ajustando hiperparámetros para gb en 37 muestras...\n",
      "2025-06-04 21:06:38,025 - INFO - wed.py:817 -     Mejores hiperparámetros para gb: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 50}\n",
      "2025-06-04 21:06:38,026 - INFO - wed.py:829 -     Entrenando gb final en 147 muestras...\n",
      "2025-06-04 21:06:38,564 - INFO - wed.py:858 -     Resultados Fold 1 (gb): AUC=0.7953, Bal.Acc=0.7295, F1=0.7368\n",
      "2025-06-04 21:06:38,567 - INFO - wed.py:863 -     Scaler latente y modelo gb del fold 1 guardados.\n",
      "2025-06-04 21:06:38,706 - INFO - wed.py:877 - Fold 1 completado en 241.00 segundos.\n",
      "2025-06-04 21:06:38,706 - INFO - wed.py:575 - --- Iniciando Fold Externo 2/10 ---\n",
      "2025-06-04 21:06:38,722 - INFO - wed.py:606 - Sujetos VAE actual train (del pool): 315, VAE internal val (del pool): 79\n",
      "2025-06-04 21:06:38,723 - INFO - wed.py:392 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 4 canales seleccionados.\n",
      "2025-06-04 21:06:38,723 - INFO - wed.py:393 - Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "2025-06-04 21:06:41,555 - INFO - wed.py:450 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.049, std=0.775)\n",
      "2025-06-04 21:06:41,757 - INFO - wed.py:450 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.056, std=0.813)\n",
      "2025-06-04 21:06:41,808 - INFO - wed.py:450 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.033, std=0.762)\n",
      "2025-06-04 21:06:41,862 - INFO - wed.py:450 - Canal 'dFC_StdDev': Off-diag zscore_offdiag (train_params: mean=0.039, std=0.715)\n",
      "2025-06-04 21:06:41,968 - INFO - wed.py:622 - Usando dispositivo: cuda\n",
      "2025-06-04 21:06:41,970 - INFO - wed.py:149 - VAE Encoder: Input Channels: 4, Num Conv Layers: 4\n",
      "2025-06-04 21:06:41,970 - INFO - wed.py:150 - VAE Encoder: Conv Channels: [16, 32, 64, 128]\n",
      "2025-06-04 21:06:41,970 - INFO - wed.py:151 - VAE Encoder: Kernels: [7, 5, 5, 3], Strides: [2, 2, 2, 2], Paddings: [1, 1, 1, 1]\n",
      "2025-06-04 21:06:41,970 - INFO - wed.py:152 - VAE Encoder: Spatial Dims (Input to Output): [131, 64, 31, 15, 8]\n",
      "2025-06-04 21:06:41,970 - INFO - wed.py:153 - VAE Encoder: Calculated flattened size after conv = 8192 (final conv output channels: 128, final spatial dim after encoder: 8)\n",
      "2025-06-04 21:06:42,048 - INFO - wed.py:187 - VAE: Intermediate FC dim (encoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:06:42,060 - INFO - wed.py:210 - VAE: Intermediate FC dim (decoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:06:42,140 - INFO - wed.py:219 - Using Upsample-Conv decoder.\n",
      "2025-06-04 21:06:42,141 - INFO - wed.py:290 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 21:06:42,186 - INFO - wed.py:640 - Entrenando VAE para el fold 2 (Decoder: upsample_conv, Encoder Layers: 4)...\n",
      "2025-06-04 21:06:45,427 - INFO - wed.py:695 - F2 VAE E5/300, TrL: 77599.2042, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 72701.7748\n",
      "2025-06-04 21:06:48,561 - INFO - wed.py:695 - F2 VAE E10/300, TrL: 73564.1304, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 71899.2679\n",
      "2025-06-04 21:06:51,717 - INFO - wed.py:695 - F2 VAE E15/300, TrL: 70578.9063, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 73098.4351\n",
      "2025-06-04 21:06:54,928 - INFO - wed.py:695 - F2 VAE E20/300, TrL: 69053.8179, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 71672.9247\n",
      "2025-06-04 21:06:58,196 - INFO - wed.py:695 - F2 VAE E25/300, TrL: 68380.7283, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 70115.0755\n",
      "2025-06-04 21:07:01,366 - INFO - wed.py:695 - F2 VAE E30/300, TrL: 67884.1521, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 69045.3787\n",
      "2025-06-04 21:07:04,593 - INFO - wed.py:695 - F2 VAE E35/300, TrL: 67532.8549, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 68469.7247\n",
      "2025-06-04 21:07:08,049 - INFO - wed.py:695 - F2 VAE E40/300, TrL: 67106.2394, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 67934.1712\n",
      "2025-06-04 21:07:11,429 - INFO - wed.py:695 - F2 VAE E45/300, TrL: 66594.0374, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 67379.8969\n",
      "2025-06-04 21:07:14,694 - INFO - wed.py:695 - F2 VAE E50/300, TrL: 66132.8173, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 66826.1159\n",
      "2025-06-04 21:07:17,842 - INFO - wed.py:695 - F2 VAE E55/300, TrL: 65549.8753, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 66165.1043\n",
      "2025-06-04 21:07:21,164 - INFO - wed.py:695 - F2 VAE E60/300, TrL: 65080.0496, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 65527.4785\n",
      "2025-06-04 21:07:24,356 - INFO - wed.py:695 - F2 VAE E65/300, TrL: 64210.4743, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 64623.1790\n",
      "2025-06-04 21:07:27,624 - INFO - wed.py:695 - F2 VAE E70/300, TrL: 63765.3803, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 64064.1842\n",
      "2025-06-04 21:07:30,989 - INFO - wed.py:695 - F2 VAE E75/300, TrL: 63350.1447, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 63510.8422\n",
      "2025-06-04 21:07:34,236 - INFO - wed.py:695 - F2 VAE E80/300, TrL: 62935.4927, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 63057.5763\n",
      "2025-06-04 21:07:37,460 - INFO - wed.py:695 - F2 VAE E85/300, TrL: 62512.2964, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 62511.4477\n",
      "2025-06-04 21:07:40,756 - INFO - wed.py:695 - F2 VAE E90/300, TrL: 62112.1076, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 61969.4915\n",
      "2025-06-04 21:07:44,007 - INFO - wed.py:695 - F2 VAE E95/300, TrL: 61764.7780, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 61645.0270\n",
      "2025-06-04 21:07:47,131 - INFO - wed.py:695 - F2 VAE E100/300, TrL: 61424.6516, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 61126.9330\n",
      "2025-06-04 21:07:50,299 - INFO - wed.py:695 - F2 VAE E105/300, TrL: 61095.7694, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 60791.7842\n",
      "2025-06-04 21:07:53,490 - INFO - wed.py:695 - F2 VAE E110/300, TrL: 60712.3591, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 60513.9153\n",
      "2025-06-04 21:07:56,723 - INFO - wed.py:695 - F2 VAE E115/300, TrL: 60440.6239, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 60248.8845\n",
      "2025-06-04 21:08:00,004 - INFO - wed.py:695 - F2 VAE E120/300, TrL: 60146.8152, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 59986.3650\n",
      "2025-06-04 21:08:03,215 - INFO - wed.py:695 - F2 VAE E125/300, TrL: 59700.4947, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 59496.9724\n",
      "2025-06-04 21:08:06,599 - INFO - wed.py:695 - F2 VAE E130/300, TrL: 59485.5339, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 59362.8523\n",
      "2025-06-04 21:08:09,811 - INFO - wed.py:695 - F2 VAE E135/300, TrL: 59302.9154, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 59228.4016\n",
      "2025-06-04 21:08:12,997 - INFO - wed.py:695 - F2 VAE E140/300, TrL: 59232.8480, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 58971.2440\n",
      "2025-06-04 21:08:16,189 - INFO - wed.py:695 - F2 VAE E145/300, TrL: 59246.7263, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 58920.0601\n",
      "2025-06-04 21:08:19,292 - INFO - wed.py:695 - F2 VAE E150/300, TrL: 58938.5575, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 58816.7684\n",
      "2025-06-04 21:08:22,596 - INFO - wed.py:695 - F2 VAE E155/300, TrL: 58751.7363, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 58509.9436\n",
      "2025-06-04 21:08:25,717 - INFO - wed.py:695 - F2 VAE E160/300, TrL: 58545.2484, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 58357.5822\n",
      "2025-06-04 21:08:28,932 - INFO - wed.py:695 - F2 VAE E165/300, TrL: 58291.6600, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 58131.6359\n",
      "2025-06-04 21:08:32,112 - INFO - wed.py:695 - F2 VAE E170/300, TrL: 58055.1353, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 58015.4677\n",
      "2025-06-04 21:08:35,453 - INFO - wed.py:695 - F2 VAE E175/300, TrL: 57961.8966, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 57764.2032\n",
      "2025-06-04 21:08:38,783 - INFO - wed.py:695 - F2 VAE E180/300, TrL: 57775.5571, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 57612.9173\n",
      "2025-06-04 21:08:41,962 - INFO - wed.py:695 - F2 VAE E185/300, TrL: 57396.3098, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 57204.0509\n",
      "2025-06-04 21:08:45,239 - INFO - wed.py:695 - F2 VAE E190/300, TrL: 57219.3793, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 57189.8059\n",
      "2025-06-04 21:08:48,579 - INFO - wed.py:695 - F2 VAE E195/300, TrL: 57157.4760, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 56947.8143\n",
      "2025-06-04 21:08:52,238 - INFO - wed.py:695 - F2 VAE E200/300, TrL: 57016.7484, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 56906.1692\n",
      "2025-06-04 21:08:56,527 - INFO - wed.py:695 - F2 VAE E205/300, TrL: 57040.3026, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 56784.8027\n",
      "2025-06-04 21:09:00,871 - INFO - wed.py:695 - F2 VAE E210/300, TrL: 56930.5097, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 56536.9449\n",
      "2025-06-04 21:09:05,255 - INFO - wed.py:695 - F2 VAE E215/300, TrL: 56701.3574, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 56554.2961\n",
      "2025-06-04 21:09:09,073 - INFO - wed.py:695 - F2 VAE E220/300, TrL: 56482.5785, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 56378.0280\n",
      "2025-06-04 21:09:13,271 - INFO - wed.py:695 - F2 VAE E225/300, TrL: 56419.5013, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 56266.9395\n",
      "2025-06-04 21:09:17,931 - INFO - wed.py:695 - F2 VAE E230/300, TrL: 56310.6320, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 56216.8005\n",
      "2025-06-04 21:09:21,219 - INFO - wed.py:695 - F2 VAE E235/300, TrL: 56035.0733, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 56026.9381\n",
      "2025-06-04 21:09:24,358 - INFO - wed.py:695 - F2 VAE E240/300, TrL: 55906.2062, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 55824.0513\n",
      "2025-06-04 21:09:27,541 - INFO - wed.py:695 - F2 VAE E245/300, TrL: 55480.4249, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 55453.1957\n",
      "2025-06-04 21:09:30,734 - INFO - wed.py:695 - F2 VAE E250/300, TrL: 55592.9949, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 55405.2014\n",
      "2025-06-04 21:09:33,932 - INFO - wed.py:695 - F2 VAE E255/300, TrL: 55360.2053, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 55374.5191\n",
      "2025-06-04 21:09:37,039 - INFO - wed.py:695 - F2 VAE E260/300, TrL: 55403.5232, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 55342.3712\n",
      "2025-06-04 21:09:40,134 - INFO - wed.py:695 - F2 VAE E265/300, TrL: 55492.6225, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 55243.7299\n",
      "2025-06-04 21:09:43,292 - INFO - wed.py:695 - F2 VAE E270/300, TrL: 55198.2482, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 55180.4571\n",
      "2025-06-04 21:09:46,498 - INFO - wed.py:695 - F2 VAE E275/300, TrL: 55071.9404, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 55133.8214\n",
      "2025-06-04 21:09:49,763 - INFO - wed.py:695 - F2 VAE E280/300, TrL: 55038.4564, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 55006.1556\n",
      "2025-06-04 21:09:52,982 - INFO - wed.py:695 - F2 VAE E285/300, TrL: 55159.9839, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54912.7371\n",
      "2025-06-04 21:09:56,181 - INFO - wed.py:695 - F2 VAE E290/300, TrL: 54912.9389, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54791.8399\n",
      "2025-06-04 21:09:59,356 - INFO - wed.py:695 - F2 VAE E295/300, TrL: 54942.4143, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54671.6406\n",
      "2025-06-04 21:10:02,565 - INFO - wed.py:695 - F2 VAE E300/300, TrL: 54762.5591, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 54550.9955\n",
      "2025-06-04 21:10:02,567 - INFO - wed.py:700 - Fold 2: VAE final model loaded (best VAE val_loss: 54550.9955).\n",
      "2025-06-04 21:10:03,161 - INFO - wed.py:704 - Modelo VAE del fold 2 guardado en: resultados_tesis/experimento_multi/fold_2/vae_model_fold_2.pt\n",
      "2025-06-04 21:10:03,358 - INFO - wed.py:782 -   --- Entrenando Clasificador: rf ---\n",
      "2025-06-04 21:10:03,359 - INFO - wed.py:814 -     Ajustando hiperparámetros para rf en 37 muestras...\n",
      "2025-06-04 21:10:31,494 - INFO - wed.py:817 -     Mejores hiperparámetros para rf: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "2025-06-04 21:10:31,495 - INFO - wed.py:829 -     Entrenando rf final en 147 muestras...\n",
      "2025-06-04 21:10:31,615 - INFO - wed.py:858 -     Resultados Fold 2 (rf): AUC=0.8012, Bal.Acc=0.6988, F1=0.7442\n",
      "2025-06-04 21:10:31,631 - INFO - wed.py:863 -     Scaler latente y modelo rf del fold 2 guardados.\n",
      "2025-06-04 21:10:31,631 - INFO - wed.py:782 -   --- Entrenando Clasificador: gb ---\n",
      "2025-06-04 21:10:31,632 - INFO - wed.py:814 -     Ajustando hiperparámetros para gb en 37 muestras...\n",
      "2025-06-04 21:10:43,436 - INFO - wed.py:817 -     Mejores hiperparámetros para gb: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 100}\n",
      "2025-06-04 21:10:43,437 - INFO - wed.py:829 -     Entrenando gb final en 147 muestras...\n",
      "2025-06-04 21:10:44,496 - INFO - wed.py:858 -     Resultados Fold 2 (gb): AUC=0.7485, Bal.Acc=0.6769, F1=0.6667\n",
      "2025-06-04 21:10:44,500 - INFO - wed.py:863 -     Scaler latente y modelo gb del fold 2 guardados.\n",
      "2025-06-04 21:10:44,670 - INFO - wed.py:877 - Fold 2 completado en 245.96 segundos.\n",
      "2025-06-04 21:10:44,670 - INFO - wed.py:575 - --- Iniciando Fold Externo 3/10 ---\n",
      "2025-06-04 21:10:44,688 - INFO - wed.py:606 - Sujetos VAE actual train (del pool): 315, VAE internal val (del pool): 79\n",
      "2025-06-04 21:10:44,688 - INFO - wed.py:392 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 4 canales seleccionados.\n",
      "2025-06-04 21:10:44,688 - INFO - wed.py:393 - Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "2025-06-04 21:10:44,764 - INFO - wed.py:450 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.048, std=0.778)\n",
      "2025-06-04 21:10:44,821 - INFO - wed.py:450 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.055, std=0.811)\n",
      "2025-06-04 21:10:44,878 - INFO - wed.py:450 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.038, std=0.768)\n",
      "2025-06-04 21:10:44,934 - INFO - wed.py:450 - Canal 'dFC_StdDev': Off-diag zscore_offdiag (train_params: mean=0.035, std=0.716)\n",
      "2025-06-04 21:10:44,952 - INFO - wed.py:622 - Usando dispositivo: cuda\n",
      "2025-06-04 21:10:44,953 - INFO - wed.py:149 - VAE Encoder: Input Channels: 4, Num Conv Layers: 4\n",
      "2025-06-04 21:10:44,953 - INFO - wed.py:150 - VAE Encoder: Conv Channels: [16, 32, 64, 128]\n",
      "2025-06-04 21:10:44,953 - INFO - wed.py:151 - VAE Encoder: Kernels: [7, 5, 5, 3], Strides: [2, 2, 2, 2], Paddings: [1, 1, 1, 1]\n",
      "2025-06-04 21:10:44,953 - INFO - wed.py:152 - VAE Encoder: Spatial Dims (Input to Output): [131, 64, 31, 15, 8]\n",
      "2025-06-04 21:10:44,953 - INFO - wed.py:153 - VAE Encoder: Calculated flattened size after conv = 8192 (final conv output channels: 128, final spatial dim after encoder: 8)\n",
      "2025-06-04 21:10:45,031 - INFO - wed.py:187 - VAE: Intermediate FC dim (encoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:10:45,042 - INFO - wed.py:210 - VAE: Intermediate FC dim (decoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:10:45,126 - INFO - wed.py:219 - Using Upsample-Conv decoder.\n",
      "2025-06-04 21:10:45,127 - INFO - wed.py:290 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 21:10:45,169 - INFO - wed.py:640 - Entrenando VAE para el fold 3 (Decoder: upsample_conv, Encoder Layers: 4)...\n",
      "2025-06-04 21:10:48,502 - INFO - wed.py:695 - F3 VAE E5/300, TrL: 77516.6037, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 69800.5340\n",
      "2025-06-04 21:10:51,796 - INFO - wed.py:695 - F3 VAE E10/300, TrL: 71045.7326, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 72026.0631\n",
      "2025-06-04 21:10:55,192 - INFO - wed.py:695 - F3 VAE E15/300, TrL: 69483.6291, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 70206.2333\n",
      "2025-06-04 21:10:58,555 - INFO - wed.py:695 - F3 VAE E20/300, TrL: 68880.9627, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 70056.8673\n",
      "2025-06-04 21:11:01,927 - INFO - wed.py:695 - F3 VAE E25/300, TrL: 68784.3408, Beta: 0.8000, LR: 1.00e-05, VAE_ValL: 69704.7901\n",
      "2025-06-04 21:11:05,337 - INFO - wed.py:695 - F3 VAE E30/300, TrL: 68775.9493, Beta: 0.9667, LR: 1.00e-05, VAE_ValL: 69735.6537\n",
      "2025-06-04 21:11:06,028 - INFO - wed.py:688 - Early stopping VAE en epoch 31. Mejor val_loss VAE: 67997.4471\n",
      "2025-06-04 21:11:06,030 - INFO - wed.py:700 - Fold 3: VAE final model loaded (best VAE val_loss: 67997.4471).\n",
      "2025-06-04 21:11:06,266 - INFO - wed.py:704 - Modelo VAE del fold 3 guardado en: resultados_tesis/experimento_multi/fold_3/vae_model_fold_3.pt\n",
      "2025-06-04 21:11:06,458 - INFO - wed.py:782 -   --- Entrenando Clasificador: rf ---\n",
      "2025-06-04 21:11:06,459 - INFO - wed.py:814 -     Ajustando hiperparámetros para rf en 37 muestras...\n",
      "2025-06-04 21:11:35,197 - INFO - wed.py:817 -     Mejores hiperparámetros para rf: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "2025-06-04 21:11:35,198 - INFO - wed.py:829 -     Entrenando rf final en 147 muestras...\n",
      "2025-06-04 21:11:35,567 - INFO - wed.py:858 -     Resultados Fold 3 (rf): AUC=0.5643, Bal.Acc=0.5950, F1=0.5946\n",
      "2025-06-04 21:11:35,617 - INFO - wed.py:863 -     Scaler latente y modelo rf del fold 3 guardados.\n",
      "2025-06-04 21:11:35,617 - INFO - wed.py:782 -   --- Entrenando Clasificador: gb ---\n",
      "2025-06-04 21:11:35,618 - INFO - wed.py:814 -     Ajustando hiperparámetros para gb en 37 muestras...\n",
      "2025-06-04 21:11:46,957 - INFO - wed.py:817 -     Mejores hiperparámetros para gb: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50}\n",
      "2025-06-04 21:11:46,957 - INFO - wed.py:829 -     Entrenando gb final en 147 muestras...\n",
      "2025-06-04 21:11:47,472 - INFO - wed.py:858 -     Resultados Fold 3 (gb): AUC=0.5702, Bal.Acc=0.5132, F1=0.5263\n",
      "2025-06-04 21:11:47,474 - INFO - wed.py:863 -     Scaler latente y modelo gb del fold 3 guardados.\n",
      "2025-06-04 21:11:47,629 - INFO - wed.py:877 - Fold 3 completado en 62.96 segundos.\n",
      "2025-06-04 21:11:47,629 - INFO - wed.py:575 - --- Iniciando Fold Externo 4/10 ---\n",
      "2025-06-04 21:11:47,645 - INFO - wed.py:606 - Sujetos VAE actual train (del pool): 315, VAE internal val (del pool): 79\n",
      "2025-06-04 21:11:47,645 - INFO - wed.py:392 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 4 canales seleccionados.\n",
      "2025-06-04 21:11:47,645 - INFO - wed.py:393 - Parámetros de normalización se calcularán usando 315 sujetos de entrenamiento.\n",
      "2025-06-04 21:11:47,719 - INFO - wed.py:450 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.045, std=0.776)\n",
      "2025-06-04 21:11:47,775 - INFO - wed.py:450 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.061, std=0.813)\n",
      "2025-06-04 21:11:47,847 - INFO - wed.py:450 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.036, std=0.767)\n",
      "2025-06-04 21:11:47,923 - INFO - wed.py:450 - Canal 'dFC_StdDev': Off-diag zscore_offdiag (train_params: mean=0.036, std=0.717)\n",
      "2025-06-04 21:11:47,952 - INFO - wed.py:622 - Usando dispositivo: cuda\n",
      "2025-06-04 21:11:47,954 - INFO - wed.py:149 - VAE Encoder: Input Channels: 4, Num Conv Layers: 4\n",
      "2025-06-04 21:11:47,954 - INFO - wed.py:150 - VAE Encoder: Conv Channels: [16, 32, 64, 128]\n",
      "2025-06-04 21:11:47,954 - INFO - wed.py:151 - VAE Encoder: Kernels: [7, 5, 5, 3], Strides: [2, 2, 2, 2], Paddings: [1, 1, 1, 1]\n",
      "2025-06-04 21:11:47,954 - INFO - wed.py:152 - VAE Encoder: Spatial Dims (Input to Output): [131, 64, 31, 15, 8]\n",
      "2025-06-04 21:11:47,954 - INFO - wed.py:153 - VAE Encoder: Calculated flattened size after conv = 8192 (final conv output channels: 128, final spatial dim after encoder: 8)\n",
      "2025-06-04 21:11:48,078 - INFO - wed.py:187 - VAE: Intermediate FC dim (encoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:11:48,098 - INFO - wed.py:210 - VAE: Intermediate FC dim (decoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:11:48,218 - INFO - wed.py:219 - Using Upsample-Conv decoder.\n",
      "2025-06-04 21:11:48,220 - INFO - wed.py:290 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 21:11:48,264 - INFO - wed.py:640 - Entrenando VAE para el fold 4 (Decoder: upsample_conv, Encoder Layers: 4)...\n",
      "2025-06-04 21:11:51,389 - INFO - wed.py:695 - F4 VAE E5/300, TrL: 74585.9969, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 69260.2997\n",
      "2025-06-04 21:11:54,528 - INFO - wed.py:695 - F4 VAE E10/300, TrL: 70567.8282, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 73055.2539\n",
      "2025-06-04 21:11:57,632 - INFO - wed.py:695 - F4 VAE E15/300, TrL: 69211.0387, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 70451.1418\n",
      "2025-06-04 21:12:00,741 - INFO - wed.py:695 - F4 VAE E20/300, TrL: 68759.9919, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 69836.3546\n",
      "2025-06-04 21:12:03,976 - INFO - wed.py:695 - F4 VAE E25/300, TrL: 68537.6592, Beta: 0.8000, LR: 1.00e-05, VAE_ValL: 69530.4126\n",
      "2025-06-04 21:12:07,144 - INFO - wed.py:695 - F4 VAE E30/300, TrL: 68496.8582, Beta: 0.9667, LR: 1.00e-05, VAE_ValL: 69537.8244\n",
      "2025-06-04 21:12:07,840 - INFO - wed.py:688 - Early stopping VAE en epoch 31. Mejor val_loss VAE: 68408.2354\n",
      "2025-06-04 21:12:07,842 - INFO - wed.py:700 - Fold 4: VAE final model loaded (best VAE val_loss: 68408.2354).\n",
      "2025-06-04 21:12:08,065 - INFO - wed.py:704 - Modelo VAE del fold 4 guardado en: resultados_tesis/experimento_multi/fold_4/vae_model_fold_4.pt\n",
      "2025-06-04 21:12:08,252 - INFO - wed.py:782 -   --- Entrenando Clasificador: rf ---\n",
      "2025-06-04 21:12:08,253 - INFO - wed.py:814 -     Ajustando hiperparámetros para rf en 37 muestras...\n",
      "2025-06-04 21:12:35,286 - INFO - wed.py:817 -     Mejores hiperparámetros para rf: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "2025-06-04 21:12:35,286 - INFO - wed.py:829 -     Entrenando rf final en 147 muestras...\n",
      "2025-06-04 21:12:35,351 - INFO - wed.py:858 -     Resultados Fold 4 (rf): AUC=0.7895, Bal.Acc=0.7281, F1=0.7500\n",
      "2025-06-04 21:12:35,360 - INFO - wed.py:863 -     Scaler latente y modelo rf del fold 4 guardados.\n",
      "2025-06-04 21:12:35,360 - INFO - wed.py:782 -   --- Entrenando Clasificador: gb ---\n",
      "2025-06-04 21:12:35,361 - INFO - wed.py:814 -     Ajustando hiperparámetros para gb en 37 muestras...\n",
      "2025-06-04 21:12:47,008 - INFO - wed.py:817 -     Mejores hiperparámetros para gb: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 100}\n",
      "2025-06-04 21:12:47,008 - INFO - wed.py:829 -     Entrenando gb final en 147 muestras...\n",
      "2025-06-04 21:12:48,032 - INFO - wed.py:858 -     Resultados Fold 4 (gb): AUC=0.5819, Bal.Acc=0.5673, F1=0.5789\n",
      "2025-06-04 21:12:48,035 - INFO - wed.py:863 -     Scaler latente y modelo gb del fold 4 guardados.\n",
      "2025-06-04 21:12:48,190 - INFO - wed.py:877 - Fold 4 completado en 60.56 segundos.\n",
      "2025-06-04 21:12:48,190 - INFO - wed.py:575 - --- Iniciando Fold Externo 5/10 ---\n",
      "2025-06-04 21:12:48,208 - INFO - wed.py:606 - Sujetos VAE actual train (del pool): 316, VAE internal val (del pool): 79\n",
      "2025-06-04 21:12:48,208 - INFO - wed.py:392 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 4 canales seleccionados.\n",
      "2025-06-04 21:12:48,208 - INFO - wed.py:393 - Parámetros de normalización se calcularán usando 316 sujetos de entrenamiento.\n",
      "2025-06-04 21:12:48,281 - INFO - wed.py:450 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag zscore_offdiag (train_params: mean=-0.045, std=0.777)\n",
      "2025-06-04 21:12:48,331 - INFO - wed.py:450 - Canal 'MI_KNN_Symmetric': Off-diag zscore_offdiag (train_params: mean=0.058, std=0.815)\n",
      "2025-06-04 21:12:48,384 - INFO - wed.py:450 - Canal 'dFC_AbsDiffMean': Off-diag zscore_offdiag (train_params: mean=-0.039, std=0.771)\n",
      "2025-06-04 21:12:48,438 - INFO - wed.py:450 - Canal 'dFC_StdDev': Off-diag zscore_offdiag (train_params: mean=0.031, std=0.713)\n",
      "2025-06-04 21:12:48,454 - INFO - wed.py:622 - Usando dispositivo: cuda\n",
      "2025-06-04 21:12:48,456 - INFO - wed.py:149 - VAE Encoder: Input Channels: 4, Num Conv Layers: 4\n",
      "2025-06-04 21:12:48,456 - INFO - wed.py:150 - VAE Encoder: Conv Channels: [16, 32, 64, 128]\n",
      "2025-06-04 21:12:48,456 - INFO - wed.py:151 - VAE Encoder: Kernels: [7, 5, 5, 3], Strides: [2, 2, 2, 2], Paddings: [1, 1, 1, 1]\n",
      "2025-06-04 21:12:48,456 - INFO - wed.py:152 - VAE Encoder: Spatial Dims (Input to Output): [131, 64, 31, 15, 8]\n",
      "2025-06-04 21:12:48,456 - INFO - wed.py:153 - VAE Encoder: Calculated flattened size after conv = 8192 (final conv output channels: 128, final spatial dim after encoder: 8)\n",
      "2025-06-04 21:12:48,542 - INFO - wed.py:187 - VAE: Intermediate FC dim (encoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:12:48,553 - INFO - wed.py:210 - VAE: Intermediate FC dim (decoder): 2048. Using LayerNorm: True\n",
      "2025-06-04 21:12:48,628 - INFO - wed.py:219 - Using Upsample-Conv decoder.\n",
      "2025-06-04 21:12:48,629 - INFO - wed.py:290 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 21:12:48,669 - INFO - wed.py:640 - Entrenando VAE para el fold 5 (Decoder: upsample_conv, Encoder Layers: 4)...\n",
      "2025-06-04 21:12:51,789 - INFO - wed.py:695 - F5 VAE E5/300, TrL: 76166.9045, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 69976.2572\n",
      "2025-06-04 21:12:54,928 - INFO - wed.py:695 - F5 VAE E10/300, TrL: 71462.3991, Beta: 0.3000, LR: 1.00e-04, VAE_ValL: 68405.9265\n",
      "2025-06-04 21:12:58,134 - INFO - wed.py:695 - F5 VAE E15/300, TrL: 69443.8474, Beta: 0.4667, LR: 1.00e-04, VAE_ValL: 67360.7574\n",
      "2025-06-04 21:13:01,269 - INFO - wed.py:695 - F5 VAE E20/300, TrL: 68580.2191, Beta: 0.6333, LR: 1.00e-04, VAE_ValL: 66792.3967\n",
      "2025-06-04 21:13:04,385 - INFO - wed.py:695 - F5 VAE E25/300, TrL: 67991.4525, Beta: 0.8000, LR: 1.00e-04, VAE_ValL: 66341.3536\n",
      "2025-06-04 21:13:07,580 - INFO - wed.py:695 - F5 VAE E30/300, TrL: 67480.4052, Beta: 0.9667, LR: 1.00e-04, VAE_ValL: 65915.6567\n",
      "2025-06-04 21:13:10,749 - INFO - wed.py:695 - F5 VAE E35/300, TrL: 67091.1909, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 65420.3220\n",
      "2025-06-04 21:13:13,904 - INFO - wed.py:695 - F5 VAE E40/300, TrL: 66603.6858, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 64932.9980\n",
      "2025-06-04 21:13:16,960 - INFO - wed.py:695 - F5 VAE E45/300, TrL: 66041.7838, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 64391.3058\n",
      "2025-06-04 21:13:19,998 - INFO - wed.py:695 - F5 VAE E50/300, TrL: 65666.2673, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 63846.6058\n",
      "2025-06-04 21:13:23,092 - INFO - wed.py:695 - F5 VAE E55/300, TrL: 65304.2638, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 63290.2886\n",
      "2025-06-04 21:13:26,248 - INFO - wed.py:695 - F5 VAE E60/300, TrL: 64709.1433, Beta: 1.0000, LR: 1.00e-04, VAE_ValL: 62796.7547\n",
      "2025-06-04 21:13:29,359 - INFO - wed.py:695 - F5 VAE E65/300, TrL: 63989.7956, Beta: 0.1333, LR: 1.00e-04, VAE_ValL: 62045.0637\n",
      "Exception ignored in: <function _releaseLock at 0x7f13f5aa85e0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/anaconda3/lib/python3.11/logging/__init__.py\", line 237, in _releaseLock\n",
      "    def _releaseLock():\n",
      "    \n",
      "KeyboardInterrupt: \n",
      "^C\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/diego/Escritorio/AAL3/wed.py\", line 1026, in <module>\n",
      "    train_and_evaluate_pipeline(global_tensor_data, metadata_df_full, args)\n",
      "  File \"/home/diego/Escritorio/AAL3/wed.py\", line 652, in train_and_evaluate_pipeline\n",
      "    for (data,) in vae_train_loader:\n",
      "  File \"/home/diego/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 440, in __iter__\n",
      "    return self._get_iterator()\n",
      "           ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/diego/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 388, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/diego/anaconda3/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1020, in __init__\n",
      "    index_queue = multiprocessing_context.Queue()  # type: ignore[var-annotated]\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/diego/anaconda3/lib/python3.11/multiprocessing/context.py\", line 103, in Queue\n",
      "    return Queue(maxsize, ctx=self.get_context())\n",
      "                              ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/diego/anaconda3/lib/python3.11/multiprocessing/context.py\", line 237, in get_context\n",
      "    def get_context(self, method=None):\n",
      "\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python wed.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path      /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv \\\n",
    "    --output_dir ./resultados_tesis/experimento_multi \\\n",
    "    --channels_to_use 1 2 3 4 \\\n",
    "    --outer_folds 5 \\\n",
    "    --repeated_outer_folds_n_repeats 2 \\\n",
    "    --inner_folds 5 \\\n",
    "    --classifier_stratify_cols Sex \\\n",
    "    --classifier_hp_tune_ratio 0.25 \\\n",
    "    --num_conv_layers_encoder 4 \\\n",
    "    --decoder_type upsample_conv \\\n",
    "    --latent_dim 512 \\\n",
    "    --lr_vae 1e-4 \\\n",
    "    --epochs_vae 300 \\\n",
    "    --batch_size 32 \\\n",
    "    --beta_vae 1.0 \\\n",
    "    --cyclical_beta_n_cycles 5 \\\n",
    "    --cyclical_beta_ratio_increase 0.5 \\\n",
    "    --weight_decay_vae 1e-5 \\\n",
    "    --vae_final_activation tanh \\\n",
    "    --intermediate_fc_dim_vae quarter \\\n",
    "    --dropout_rate_vae 0.3 \\\n",
    "    --use_layernorm_vae_fc \\\n",
    "    --vae_val_split_ratio 0.2 \\\n",
    "    --early_stopping_patience_vae 30 \\\n",
    "    --lr_scheduler_patience_vae 20 \\\n",
    "    --classifier_types rf gb \\\n",
    "    --latent_features_type mu \\\n",
    "    --gridsearch_scoring balanced_accuracy \\\n",
    "    --classifier_use_class_weight \\\n",
    "    --norm_mode zscore_offdiag \\\n",
    "    --seed 42 \\\n",
    "    --num_workers 4 \\\n",
    "    --n_jobs_gridsearch 4 \\\n",
    "    --log_interval_epochs_vae 5 \\\n",
    "    --save_fold_artefacts \\\n",
    "    --save_vae_training_history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
