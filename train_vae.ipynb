{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffb3d430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-04 15:59:50,806 - INFO - train_vae_classifier.py:275 - Cargando tensor global desde: /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz\n",
      "2025-06-04 15:59:51,296 - INFO - train_vae_classifier.py:283 - Tensor global cargado. Forma: (431, 6, 131, 131)\n",
      "2025-06-04 15:59:51,296 - INFO - train_vae_classifier.py:290 - Cargando metadatos desde: /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv\n",
      "2025-06-04 15:59:51,300 - INFO - train_vae_classifier.py:297 - Metadatos cargados. Forma: (434, 24)\n",
      "2025-06-04 15:59:51,302 - INFO - train_vae_classifier.py:778 - Canales a usar: ['1', '2', '3']\n",
      "2025-06-04 15:59:51,302 - INFO - train_vae_classifier.py:779 - Modo de normalización: zscore_offdiag\n",
      "2025-06-04 15:59:51,302 - INFO - train_vae_classifier.py:780 - Activación final VAE: tanh\n",
      "2025-06-04 15:59:51,302 - INFO - train_vae_classifier.py:462 - Usando canales seleccionados (índices originales): [1, 2, 3]\n",
      "2025-06-04 15:59:51,302 - INFO - train_vae_classifier.py:463 - Nombres de canales seleccionados: ['Pearson_Full_FisherZ_Signed', 'MI_KNN_Symmetric', 'dFC_AbsDiffMean']\n",
      "2025-06-04 15:59:51,320 - INFO - train_vae_classifier.py:490 - Estratificando folds del clasificador por ResearchGroup y Sex.\n",
      "2025-06-04 15:59:51,320 - INFO - train_vae_classifier.py:500 - Iniciando clasificación CN vs AD. Total sujetos CN/AD: 184. CN: 89, AD: 95\n",
      "2025-06-04 15:59:51,321 - INFO - train_vae_classifier.py:509 - --- Iniciando Fold Externo 1/5 ---\n",
      "2025-06-04 15:59:51,334 - INFO - train_vae_classifier.py:534 - Normalizando datos para VAE...\n",
      "2025-06-04 15:59:51,334 - INFO - train_vae_classifier.py:322 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados, usando parámetros de entrenamiento.\n",
      "2025-06-04 15:59:51,770 - INFO - train_vae_classifier.py:392 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag Z-score (train_mean=-0.047, train_std=0.777).\n",
      "2025-06-04 15:59:52,219 - INFO - train_vae_classifier.py:392 - Canal 'MI_KNN_Symmetric': Off-diag Z-score (train_mean=0.060, train_std=0.816).\n",
      "2025-06-04 15:59:52,647 - INFO - train_vae_classifier.py:392 - Canal 'dFC_AbsDiffMean': Off-diag Z-score (train_mean=-0.036, train_std=0.771).\n",
      "2025-06-04 15:59:52,662 - INFO - train_vae_classifier.py:551 - Usando dispositivo: cuda\n",
      "2025-06-04 15:59:52,689 - INFO - train_vae_classifier.py:109 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 15:59:52,689 - INFO - train_vae_classifier.py:110 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 15:59:52,689 - INFO - train_vae_classifier.py:136 - VAE: Input dimension to fc_mu/fc_logvar: 18496.\n",
      "2025-06-04 15:59:52,689 - INFO - train_vae_classifier.py:138 - VAE: Based on this, a suggested latent_dim could be: 9248 (current is 512).\n",
      "2025-06-04 15:59:52,836 - INFO - train_vae_classifier.py:207 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 15:59:53,343 - INFO - train_vae_classifier.py:568 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 15:59:53,343 - INFO - train_vae_classifier.py:570 - Entrenando VAE para el fold 1...\n",
      "2025-06-04 15:59:58,003 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 10/450, Train Loss: 39428.1995, LR: 1.00e-04, Val Loss: 39733.6607\n",
      "2025-06-04 16:00:02,144 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 20/450, Train Loss: 34044.4622, LR: 1.00e-04, Val Loss: 34705.0932\n",
      "2025-06-04 16:00:06,226 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 30/450, Train Loss: 31283.9324, LR: 1.00e-04, Val Loss: 32484.2052\n",
      "2025-06-04 16:00:10,388 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 40/450, Train Loss: 29449.3182, LR: 1.00e-04, Val Loss: 31003.5568\n",
      "2025-06-04 16:00:14,579 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 50/450, Train Loss: 28142.2095, LR: 1.00e-04, Val Loss: 30300.5068\n",
      "2025-06-04 16:00:18,896 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 60/450, Train Loss: 27060.0691, LR: 1.00e-04, Val Loss: 29480.3227\n",
      "2025-06-04 16:00:23,041 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 70/450, Train Loss: 26243.8312, LR: 1.00e-04, Val Loss: 29032.1341\n",
      "2025-06-04 16:00:27,250 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 80/450, Train Loss: 25555.8995, LR: 1.00e-04, Val Loss: 28635.6764\n",
      "2025-06-04 16:00:31,565 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 90/450, Train Loss: 24924.3160, LR: 1.00e-04, Val Loss: 28332.9697\n",
      "2025-06-04 16:00:35,789 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 100/450, Train Loss: 24426.3872, LR: 1.00e-04, Val Loss: 28047.6491\n",
      "2025-06-04 16:00:40,032 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 110/450, Train Loss: 23924.8216, LR: 1.00e-04, Val Loss: 27831.6254\n",
      "2025-06-04 16:00:44,211 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 120/450, Train Loss: 23504.2863, LR: 1.00e-04, Val Loss: 27671.7056\n",
      "2025-06-04 16:00:48,297 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 130/450, Train Loss: 23141.9915, LR: 1.00e-04, Val Loss: 27699.6451\n",
      "2025-06-04 16:00:52,361 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 140/450, Train Loss: 22806.5995, LR: 1.00e-04, Val Loss: 27598.5695\n",
      "2025-06-04 16:00:56,468 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 150/450, Train Loss: 22513.1294, LR: 1.00e-04, Val Loss: 27503.7496\n",
      "2025-06-04 16:01:00,606 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 160/450, Train Loss: 22213.1535, LR: 1.00e-04, Val Loss: 27644.3553\n",
      "2025-06-04 16:01:04,768 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 170/450, Train Loss: 21958.8541, LR: 1.00e-04, Val Loss: 27462.7293\n",
      "2025-06-04 16:01:08,985 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 180/450, Train Loss: 21651.1173, LR: 1.00e-04, Val Loss: 27411.6757\n",
      "2025-06-04 16:01:13,117 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 190/450, Train Loss: 21462.6093, LR: 1.00e-04, Val Loss: 27417.8852\n",
      "2025-06-04 16:01:17,253 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 200/450, Train Loss: 21232.5843, LR: 1.00e-04, Val Loss: 27391.0410\n",
      "2025-06-04 16:01:21,317 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 210/450, Train Loss: 20945.8788, LR: 1.00e-05, Val Loss: 27217.1049\n",
      "2025-06-04 16:01:25,453 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 220/450, Train Loss: 20880.7215, LR: 1.00e-05, Val Loss: 27184.3794\n",
      "2025-06-04 16:01:29,541 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 230/450, Train Loss: 20816.7394, LR: 1.00e-05, Val Loss: 27188.1358\n",
      "2025-06-04 16:01:33,606 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 240/450, Train Loss: 20773.8776, LR: 1.00e-06, Val Loss: 27172.3917\n",
      "2025-06-04 16:01:37,705 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 250/450, Train Loss: 20769.3355, LR: 1.00e-07, Val Loss: 27176.3845\n",
      "2025-06-04 16:01:41,810 - INFO - train_vae_classifier.py:618 - Fold 1, VAE Epoch 260/450, Train Loss: 20768.4239, LR: 1.00e-07, Val Loss: 27165.6074\n",
      "2025-06-04 16:01:44,299 - INFO - train_vae_classifier.py:614 - Fold 1: Early stopping VAE en epoch 266. Mejor val_loss: 27146.4305\n",
      "2025-06-04 16:01:44,299 - INFO - train_vae_classifier.py:621 - Fold 1: Cargando mejor modelo VAE con val_loss: 27146.4305\n",
      "2025-06-04 16:01:44,764 - INFO - train_vae_classifier.py:628 - Modelo VAE del fold 1 guardado en: resultados/corrida_zscore_tanh_v1.3/vae_fold_1_ld512_beta1.0_ch3.pt\n",
      "2025-06-04 16:01:44,770 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:01:44,794 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:01:44,814 - INFO - train_vae_classifier.py:663 - Entrenando clasificador SVM para el fold 1...\n",
      "2025-06-04 16:01:45,706 - INFO - train_vae_classifier.py:665 - Mejores hiperparámetros SVM para fold 1: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 16:01:45,711 - INFO - train_vae_classifier.py:677 - Fold 1 - Resultados Clasificador:\n",
      "2025-06-04 16:01:45,711 - INFO - train_vae_classifier.py:678 -   AUC: 0.7398, PR-AUC: 0.8095, Acc: 0.7838\n",
      "2025-06-04 16:01:45,711 - INFO - train_vae_classifier.py:679 -   Sens (AD): 0.6842, Spec (CN): 0.8889, F1 (AD): 0.7647\n",
      "2025-06-04 16:01:45,711 - INFO - train_vae_classifier.py:686 -   Fold 1 Train (Clf) IDs Hash: 2779e701cd59ce68bb0effac6ef92418\n",
      "2025-06-04 16:01:45,711 - INFO - train_vae_classifier.py:687 -   Fold 1 Test (Clf) IDs Hash: 8d5238afcd0c3527c607e2b6bf4e9522\n",
      "2025-06-04 16:01:45,813 - INFO - train_vae_classifier.py:509 - --- Iniciando Fold Externo 2/5 ---\n",
      "2025-06-04 16:01:45,825 - INFO - train_vae_classifier.py:534 - Normalizando datos para VAE...\n",
      "2025-06-04 16:01:45,825 - INFO - train_vae_classifier.py:322 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados, usando parámetros de entrenamiento.\n",
      "2025-06-04 16:01:46,270 - INFO - train_vae_classifier.py:392 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag Z-score (train_mean=-0.048, train_std=0.776).\n",
      "2025-06-04 16:01:46,692 - INFO - train_vae_classifier.py:392 - Canal 'MI_KNN_Symmetric': Off-diag Z-score (train_mean=0.055, train_std=0.813).\n",
      "2025-06-04 16:01:47,110 - INFO - train_vae_classifier.py:392 - Canal 'dFC_AbsDiffMean': Off-diag Z-score (train_mean=-0.037, train_std=0.767).\n",
      "2025-06-04 16:01:47,126 - INFO - train_vae_classifier.py:551 - Usando dispositivo: cuda\n",
      "2025-06-04 16:01:47,128 - INFO - train_vae_classifier.py:109 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 16:01:47,128 - INFO - train_vae_classifier.py:110 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 16:01:47,129 - INFO - train_vae_classifier.py:136 - VAE: Input dimension to fc_mu/fc_logvar: 18496.\n",
      "2025-06-04 16:01:47,129 - INFO - train_vae_classifier.py:138 - VAE: Based on this, a suggested latent_dim could be: 9248 (current is 512).\n",
      "2025-06-04 16:01:47,320 - INFO - train_vae_classifier.py:207 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 16:01:47,344 - INFO - train_vae_classifier.py:568 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 16:01:47,344 - INFO - train_vae_classifier.py:570 - Entrenando VAE para el fold 2...\n",
      "2025-06-04 16:01:51,536 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 10/450, Train Loss: 39763.1166, LR: 1.00e-04, Val Loss: 40117.4034\n",
      "2025-06-04 16:01:55,734 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 20/450, Train Loss: 34170.4859, LR: 1.00e-04, Val Loss: 34886.2885\n",
      "2025-06-04 16:01:59,839 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 30/450, Train Loss: 31366.6677, LR: 1.00e-04, Val Loss: 32595.2331\n",
      "2025-06-04 16:02:03,895 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 40/450, Train Loss: 29547.3294, LR: 1.00e-04, Val Loss: 31136.1201\n",
      "2025-06-04 16:02:08,030 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 50/450, Train Loss: 28272.4814, LR: 1.00e-04, Val Loss: 30370.2250\n",
      "2025-06-04 16:02:12,139 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 60/450, Train Loss: 27222.8856, LR: 1.00e-04, Val Loss: 29583.7729\n",
      "2025-06-04 16:02:16,279 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 70/450, Train Loss: 26255.9035, LR: 1.00e-04, Val Loss: 29104.3220\n",
      "2025-06-04 16:02:20,501 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 80/450, Train Loss: 25508.5237, LR: 1.00e-04, Val Loss: 28777.0892\n",
      "2025-06-04 16:02:24,587 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 90/450, Train Loss: 24891.7933, LR: 1.00e-04, Val Loss: 28659.7536\n",
      "2025-06-04 16:02:28,768 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 100/450, Train Loss: 24320.8692, LR: 1.00e-04, Val Loss: 28278.8526\n",
      "2025-06-04 16:02:32,858 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 110/450, Train Loss: 23851.7375, LR: 1.00e-04, Val Loss: 28043.1124\n",
      "2025-06-04 16:02:36,994 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 120/450, Train Loss: 23468.3174, LR: 1.00e-04, Val Loss: 27959.1328\n",
      "2025-06-04 16:02:41,048 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 130/450, Train Loss: 23000.3241, LR: 1.00e-04, Val Loss: 27934.2017\n",
      "2025-06-04 16:02:45,155 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 140/450, Train Loss: 22700.3785, LR: 1.00e-04, Val Loss: 28053.0227\n",
      "2025-06-04 16:02:49,272 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 150/450, Train Loss: 22331.1514, LR: 1.00e-04, Val Loss: 27752.6694\n",
      "2025-06-04 16:02:53,344 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 160/450, Train Loss: 22051.4905, LR: 1.00e-04, Val Loss: 27676.8542\n",
      "2025-06-04 16:02:57,495 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 170/450, Train Loss: 21753.6748, LR: 1.00e-04, Val Loss: 27732.1012\n",
      "2025-06-04 16:03:01,572 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 180/450, Train Loss: 21519.3051, LR: 1.00e-04, Val Loss: 27534.5815\n",
      "2025-06-04 16:03:05,626 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 190/450, Train Loss: 21246.6685, LR: 1.00e-04, Val Loss: 27629.8104\n",
      "2025-06-04 16:03:09,790 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 200/450, Train Loss: 20926.0636, LR: 1.00e-05, Val Loss: 27478.9897\n",
      "2025-06-04 16:03:13,929 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 210/450, Train Loss: 20821.4700, LR: 1.00e-05, Val Loss: 27486.1061\n",
      "2025-06-04 16:03:18,145 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 220/450, Train Loss: 20784.3186, LR: 1.00e-05, Val Loss: 27496.3712\n",
      "2025-06-04 16:03:22,266 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 230/450, Train Loss: 20748.6902, LR: 1.00e-05, Val Loss: 27509.8424\n",
      "2025-06-04 16:03:26,385 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 240/450, Train Loss: 20707.4949, LR: 1.00e-06, Val Loss: 27498.1063\n",
      "2025-06-04 16:03:30,595 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 250/450, Train Loss: 20701.2965, LR: 1.00e-07, Val Loss: 27505.1163\n",
      "2025-06-04 16:03:34,909 - INFO - train_vae_classifier.py:618 - Fold 2, VAE Epoch 260/450, Train Loss: 20728.1892, LR: 1.00e-07, Val Loss: 27480.6182\n",
      "2025-06-04 16:03:37,023 - INFO - train_vae_classifier.py:614 - Fold 2: Early stopping VAE en epoch 265. Mejor val_loss: 27457.1337\n",
      "2025-06-04 16:03:37,024 - INFO - train_vae_classifier.py:621 - Fold 2: Cargando mejor modelo VAE con val_loss: 27457.1337\n",
      "2025-06-04 16:03:37,557 - INFO - train_vae_classifier.py:628 - Modelo VAE del fold 2 guardado en: resultados/corrida_zscore_tanh_v1.3/vae_fold_2_ld512_beta1.0_ch3.pt\n",
      "2025-06-04 16:03:37,563 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:03:37,586 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:03:37,605 - INFO - train_vae_classifier.py:663 - Entrenando clasificador SVM para el fold 2...\n",
      "2025-06-04 16:03:38,428 - INFO - train_vae_classifier.py:665 - Mejores hiperparámetros SVM para fold 2: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 16:03:38,432 - INFO - train_vae_classifier.py:677 - Fold 2 - Resultados Clasificador:\n",
      "2025-06-04 16:03:38,433 - INFO - train_vae_classifier.py:678 -   AUC: 0.7427, PR-AUC: 0.7432, Acc: 0.6486\n",
      "2025-06-04 16:03:38,433 - INFO - train_vae_classifier.py:679 -   Sens (AD): 0.5789, Spec (CN): 0.7222, F1 (AD): 0.6286\n",
      "2025-06-04 16:03:38,433 - INFO - train_vae_classifier.py:686 -   Fold 2 Train (Clf) IDs Hash: b5e994794b74a9904266a125cdf091f5\n",
      "2025-06-04 16:03:38,433 - INFO - train_vae_classifier.py:687 -   Fold 2 Test (Clf) IDs Hash: 75fb70d543639e48b92116fb9ac3a15c\n",
      "2025-06-04 16:03:38,537 - INFO - train_vae_classifier.py:509 - --- Iniciando Fold Externo 3/5 ---\n",
      "2025-06-04 16:03:38,549 - INFO - train_vae_classifier.py:534 - Normalizando datos para VAE...\n",
      "2025-06-04 16:03:38,549 - INFO - train_vae_classifier.py:322 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados, usando parámetros de entrenamiento.\n",
      "2025-06-04 16:03:39,012 - INFO - train_vae_classifier.py:392 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag Z-score (train_mean=-0.048, train_std=0.776).\n",
      "2025-06-04 16:03:39,452 - INFO - train_vae_classifier.py:392 - Canal 'MI_KNN_Symmetric': Off-diag Z-score (train_mean=0.057, train_std=0.815).\n",
      "2025-06-04 16:03:39,863 - INFO - train_vae_classifier.py:392 - Canal 'dFC_AbsDiffMean': Off-diag Z-score (train_mean=-0.037, train_std=0.770).\n",
      "2025-06-04 16:03:39,881 - INFO - train_vae_classifier.py:551 - Usando dispositivo: cuda\n",
      "2025-06-04 16:03:39,883 - INFO - train_vae_classifier.py:109 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 16:03:39,883 - INFO - train_vae_classifier.py:110 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 16:03:39,883 - INFO - train_vae_classifier.py:136 - VAE: Input dimension to fc_mu/fc_logvar: 18496.\n",
      "2025-06-04 16:03:39,883 - INFO - train_vae_classifier.py:138 - VAE: Based on this, a suggested latent_dim could be: 9248 (current is 512).\n",
      "2025-06-04 16:03:40,074 - INFO - train_vae_classifier.py:207 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 16:03:40,098 - INFO - train_vae_classifier.py:568 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 16:03:40,098 - INFO - train_vae_classifier.py:570 - Entrenando VAE para el fold 3...\n",
      "2025-06-04 16:03:44,382 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 10/450, Train Loss: 39636.3388, LR: 1.00e-04, Val Loss: 39438.0385\n",
      "2025-06-04 16:03:48,719 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 20/450, Train Loss: 34229.6137, LR: 1.00e-04, Val Loss: 34231.0229\n",
      "2025-06-04 16:03:52,949 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 30/450, Train Loss: 31393.7363, LR: 1.00e-04, Val Loss: 31926.4740\n",
      "2025-06-04 16:03:57,088 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 40/450, Train Loss: 29544.8202, LR: 1.00e-04, Val Loss: 30548.6514\n",
      "2025-06-04 16:04:01,209 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 50/450, Train Loss: 28198.3294, LR: 1.00e-04, Val Loss: 29963.3716\n",
      "2025-06-04 16:04:05,306 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 60/450, Train Loss: 27115.7676, LR: 1.00e-04, Val Loss: 29158.6441\n",
      "2025-06-04 16:04:09,511 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 70/450, Train Loss: 26190.5687, LR: 1.00e-04, Val Loss: 28858.7552\n",
      "2025-06-04 16:04:13,640 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 80/450, Train Loss: 25451.6754, LR: 1.00e-04, Val Loss: 28346.9562\n",
      "2025-06-04 16:04:17,888 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 90/450, Train Loss: 24888.6754, LR: 1.00e-04, Val Loss: 28340.0366\n",
      "2025-06-04 16:04:22,207 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 100/450, Train Loss: 24354.1453, LR: 1.00e-04, Val Loss: 27878.0000\n",
      "2025-06-04 16:04:26,396 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 110/450, Train Loss: 23845.4295, LR: 1.00e-04, Val Loss: 27637.6839\n",
      "2025-06-04 16:04:30,534 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 120/450, Train Loss: 23453.4175, LR: 1.00e-04, Val Loss: 27653.8423\n",
      "2025-06-04 16:04:34,693 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 130/450, Train Loss: 23070.3193, LR: 1.00e-04, Val Loss: 27451.3939\n",
      "2025-06-04 16:04:38,822 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 140/450, Train Loss: 22763.2301, LR: 1.00e-04, Val Loss: 27403.2457\n",
      "2025-06-04 16:04:43,009 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 150/450, Train Loss: 22483.3653, LR: 1.00e-04, Val Loss: 27245.4861\n",
      "2025-06-04 16:04:47,077 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 160/450, Train Loss: 22140.0093, LR: 1.00e-04, Val Loss: 27185.6371\n",
      "2025-06-04 16:04:51,276 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 170/450, Train Loss: 21825.8428, LR: 1.00e-04, Val Loss: 27146.2549\n",
      "2025-06-04 16:04:55,533 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 180/450, Train Loss: 21627.8794, LR: 1.00e-04, Val Loss: 27271.4337\n",
      "2025-06-04 16:04:59,705 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 190/450, Train Loss: 21369.4328, LR: 1.00e-04, Val Loss: 27269.7590\n",
      "2025-06-04 16:05:03,799 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 200/450, Train Loss: 21057.1921, LR: 1.00e-05, Val Loss: 27044.9568\n",
      "2025-06-04 16:05:07,957 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 210/450, Train Loss: 20983.2597, LR: 1.00e-05, Val Loss: 27028.4659\n",
      "2025-06-04 16:05:12,110 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 220/450, Train Loss: 20928.2069, LR: 1.00e-06, Val Loss: 27044.3641\n",
      "2025-06-04 16:05:16,308 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 230/450, Train Loss: 20906.1426, LR: 1.00e-06, Val Loss: 27041.5986\n",
      "2025-06-04 16:05:20,513 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 240/450, Train Loss: 20915.0186, LR: 1.00e-07, Val Loss: 27018.8194\n",
      "2025-06-04 16:05:24,766 - INFO - train_vae_classifier.py:618 - Fold 3, VAE Epoch 250/450, Train Loss: 20898.1264, LR: 1.00e-07, Val Loss: 27021.5633\n",
      "2025-06-04 16:05:26,029 - INFO - train_vae_classifier.py:614 - Fold 3: Early stopping VAE en epoch 253. Mejor val_loss: 27004.0913\n",
      "2025-06-04 16:05:26,029 - INFO - train_vae_classifier.py:621 - Fold 3: Cargando mejor modelo VAE con val_loss: 27004.0913\n",
      "2025-06-04 16:05:26,846 - INFO - train_vae_classifier.py:628 - Modelo VAE del fold 3 guardado en: resultados/corrida_zscore_tanh_v1.3/vae_fold_3_ld512_beta1.0_ch3.pt\n",
      "2025-06-04 16:05:26,853 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:05:26,874 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:05:26,892 - INFO - train_vae_classifier.py:663 - Entrenando clasificador SVM para el fold 3...\n",
      "2025-06-04 16:05:27,720 - INFO - train_vae_classifier.py:665 - Mejores hiperparámetros SVM para fold 3: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 16:05:27,724 - INFO - train_vae_classifier.py:677 - Fold 3 - Resultados Clasificador:\n",
      "2025-06-04 16:05:27,725 - INFO - train_vae_classifier.py:678 -   AUC: 0.8713, PR-AUC: 0.8626, Acc: 0.7568\n",
      "2025-06-04 16:05:27,725 - INFO - train_vae_classifier.py:679 -   Sens (AD): 0.7895, Spec (CN): 0.7222, F1 (AD): 0.7692\n",
      "2025-06-04 16:05:27,725 - INFO - train_vae_classifier.py:686 -   Fold 3 Train (Clf) IDs Hash: 80544096ea147ba4bea01e785b1b0296\n",
      "2025-06-04 16:05:27,725 - INFO - train_vae_classifier.py:687 -   Fold 3 Test (Clf) IDs Hash: 7d1a90c026ff2135e996d551f0eb55d2\n",
      "2025-06-04 16:05:27,829 - INFO - train_vae_classifier.py:509 - --- Iniciando Fold Externo 4/5 ---\n",
      "2025-06-04 16:05:27,842 - INFO - train_vae_classifier.py:534 - Normalizando datos para VAE...\n",
      "2025-06-04 16:05:27,842 - INFO - train_vae_classifier.py:322 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados, usando parámetros de entrenamiento.\n",
      "2025-06-04 16:05:28,311 - INFO - train_vae_classifier.py:392 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag Z-score (train_mean=-0.047, train_std=0.775).\n",
      "2025-06-04 16:05:28,737 - INFO - train_vae_classifier.py:392 - Canal 'MI_KNN_Symmetric': Off-diag Z-score (train_mean=0.057, train_std=0.810).\n",
      "2025-06-04 16:05:29,206 - INFO - train_vae_classifier.py:392 - Canal 'dFC_AbsDiffMean': Off-diag Z-score (train_mean=-0.036, train_std=0.765).\n",
      "2025-06-04 16:05:29,218 - INFO - train_vae_classifier.py:551 - Usando dispositivo: cuda\n",
      "2025-06-04 16:05:29,220 - INFO - train_vae_classifier.py:109 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 16:05:29,220 - INFO - train_vae_classifier.py:110 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 16:05:29,220 - INFO - train_vae_classifier.py:136 - VAE: Input dimension to fc_mu/fc_logvar: 18496.\n",
      "2025-06-04 16:05:29,220 - INFO - train_vae_classifier.py:138 - VAE: Based on this, a suggested latent_dim could be: 9248 (current is 512).\n",
      "2025-06-04 16:05:29,330 - INFO - train_vae_classifier.py:207 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 16:05:29,349 - INFO - train_vae_classifier.py:568 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 16:05:29,349 - INFO - train_vae_classifier.py:570 - Entrenando VAE para el fold 4...\n",
      "2025-06-04 16:05:33,573 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 10/450, Train Loss: 39578.8071, LR: 1.00e-04, Val Loss: 41331.0443\n",
      "2025-06-04 16:05:37,825 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 20/450, Train Loss: 34025.2419, LR: 1.00e-04, Val Loss: 36258.5445\n",
      "2025-06-04 16:05:42,196 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 30/450, Train Loss: 31214.2548, LR: 1.00e-04, Val Loss: 33737.4521\n",
      "2025-06-04 16:05:46,390 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 40/450, Train Loss: 29377.2618, LR: 1.00e-04, Val Loss: 32402.8961\n",
      "2025-06-04 16:05:50,684 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 50/450, Train Loss: 28045.7075, LR: 1.00e-04, Val Loss: 31534.8874\n",
      "2025-06-04 16:05:54,942 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 60/450, Train Loss: 26924.8625, LR: 1.00e-04, Val Loss: 30950.2004\n",
      "2025-06-04 16:05:59,348 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 70/450, Train Loss: 26064.1323, LR: 1.00e-04, Val Loss: 30492.0938\n",
      "2025-06-04 16:06:03,856 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 80/450, Train Loss: 25290.3233, LR: 1.00e-04, Val Loss: 30050.7069\n",
      "2025-06-04 16:06:08,281 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 90/450, Train Loss: 24659.2356, LR: 1.00e-04, Val Loss: 29772.1421\n",
      "2025-06-04 16:06:12,651 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 100/450, Train Loss: 24126.0683, LR: 1.00e-04, Val Loss: 29721.2680\n",
      "2025-06-04 16:06:17,011 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 110/450, Train Loss: 23661.4872, LR: 1.00e-04, Val Loss: 29581.9797\n",
      "2025-06-04 16:06:21,383 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 120/450, Train Loss: 23223.4146, LR: 1.00e-04, Val Loss: 29423.4599\n",
      "2025-06-04 16:06:25,705 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 130/450, Train Loss: 22856.5739, LR: 1.00e-04, Val Loss: 29251.2167\n",
      "2025-06-04 16:06:30,100 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 140/450, Train Loss: 22494.7954, LR: 1.00e-04, Val Loss: 29121.6402\n",
      "2025-06-04 16:06:34,423 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 150/450, Train Loss: 22181.6274, LR: 1.00e-04, Val Loss: 29094.0615\n",
      "2025-06-04 16:06:38,780 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 160/450, Train Loss: 21892.4000, LR: 1.00e-04, Val Loss: 29060.9560\n",
      "2025-06-04 16:06:43,150 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 170/450, Train Loss: 21679.1008, LR: 1.00e-04, Val Loss: 29023.9480\n",
      "2025-06-04 16:06:47,475 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 180/450, Train Loss: 21411.4734, LR: 1.00e-04, Val Loss: 28971.3815\n",
      "2025-06-04 16:06:51,824 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 190/450, Train Loss: 21186.8823, LR: 1.00e-04, Val Loss: 29043.6342\n",
      "2025-06-04 16:06:56,111 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 200/450, Train Loss: 20915.9567, LR: 1.00e-04, Val Loss: 28967.7793\n",
      "2025-06-04 16:07:00,648 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 210/450, Train Loss: 20698.4926, LR: 1.00e-04, Val Loss: 29105.4309\n",
      "2025-06-04 16:07:04,947 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 220/450, Train Loss: 20499.8073, LR: 1.00e-04, Val Loss: 29020.1271\n",
      "2025-06-04 16:07:09,303 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 230/450, Train Loss: 20250.5194, LR: 1.00e-05, Val Loss: 28832.3772\n",
      "2025-06-04 16:07:13,774 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 240/450, Train Loss: 20166.1639, LR: 1.00e-05, Val Loss: 28900.0003\n",
      "2025-06-04 16:07:18,199 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 250/450, Train Loss: 20137.5913, LR: 1.00e-06, Val Loss: 28869.5650\n",
      "2025-06-04 16:07:22,533 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 260/450, Train Loss: 20122.6095, LR: 1.00e-06, Val Loss: 28889.5624\n",
      "2025-06-04 16:07:26,825 - INFO - train_vae_classifier.py:618 - Fold 4, VAE Epoch 270/450, Train Loss: 20136.1472, LR: 1.00e-07, Val Loss: 28851.0721\n",
      "2025-06-04 16:07:30,995 - INFO - train_vae_classifier.py:614 - Fold 4: Early stopping VAE en epoch 280. Mejor val_loss: 28832.3772\n",
      "2025-06-04 16:07:30,995 - INFO - train_vae_classifier.py:621 - Fold 4: Cargando mejor modelo VAE con val_loss: 28832.3772\n",
      "2025-06-04 16:07:31,492 - INFO - train_vae_classifier.py:628 - Modelo VAE del fold 4 guardado en: resultados/corrida_zscore_tanh_v1.3/vae_fold_4_ld512_beta1.0_ch3.pt\n",
      "2025-06-04 16:07:31,496 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:07:31,520 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:07:31,539 - INFO - train_vae_classifier.py:663 - Entrenando clasificador SVM para el fold 4...\n",
      "2025-06-04 16:07:32,388 - INFO - train_vae_classifier.py:665 - Mejores hiperparámetros SVM para fold 4: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n",
      "2025-06-04 16:07:32,392 - INFO - train_vae_classifier.py:677 - Fold 4 - Resultados Clasificador:\n",
      "2025-06-04 16:07:32,392 - INFO - train_vae_classifier.py:678 -   AUC: 0.7339, PR-AUC: 0.7706, Acc: 0.6486\n",
      "2025-06-04 16:07:32,392 - INFO - train_vae_classifier.py:679 -   Sens (AD): 0.8421, Spec (CN): 0.4444, F1 (AD): 0.7111\n",
      "2025-06-04 16:07:32,393 - INFO - train_vae_classifier.py:686 -   Fold 4 Train (Clf) IDs Hash: 4233102bf5f5b85a82d2862cd2ebce43\n",
      "2025-06-04 16:07:32,393 - INFO - train_vae_classifier.py:687 -   Fold 4 Test (Clf) IDs Hash: 2757a917d68b11524b20e8267350abc9\n",
      "2025-06-04 16:07:32,495 - INFO - train_vae_classifier.py:509 - --- Iniciando Fold Externo 5/5 ---\n",
      "2025-06-04 16:07:32,508 - INFO - train_vae_classifier.py:534 - Normalizando datos para VAE...\n",
      "2025-06-04 16:07:32,508 - INFO - train_vae_classifier.py:322 - Aplicando normalización inter-canal (modo: zscore_offdiag) sobre 3 canales seleccionados, usando parámetros de entrenamiento.\n",
      "2025-06-04 16:07:32,949 - INFO - train_vae_classifier.py:392 - Canal 'Pearson_Full_FisherZ_Signed': Off-diag Z-score (train_mean=-0.048, train_std=0.777).\n",
      "2025-06-04 16:07:33,383 - INFO - train_vae_classifier.py:392 - Canal 'MI_KNN_Symmetric': Off-diag Z-score (train_mean=0.057, train_std=0.812).\n",
      "2025-06-04 16:07:33,788 - INFO - train_vae_classifier.py:392 - Canal 'dFC_AbsDiffMean': Off-diag Z-score (train_mean=-0.036, train_std=0.767).\n",
      "2025-06-04 16:07:33,806 - INFO - train_vae_classifier.py:551 - Usando dispositivo: cuda\n",
      "2025-06-04 16:07:33,808 - INFO - train_vae_classifier.py:109 - VAE Encoder: Input Channels: 3, Conv Channels: [16, 32, 64]\n",
      "2025-06-04 16:07:33,808 - INFO - train_vae_classifier.py:110 - VAE Encoder: Calculated flattened size after conv = 18496 (final conv output channels: 64, final spatial dim after encoder: 17)\n",
      "2025-06-04 16:07:33,808 - INFO - train_vae_classifier.py:136 - VAE: Input dimension to fc_mu/fc_logvar: 18496.\n",
      "2025-06-04 16:07:33,808 - INFO - train_vae_classifier.py:138 - VAE: Based on this, a suggested latent_dim could be: 9248 (current is 512).\n",
      "2025-06-04 16:07:34,001 - INFO - train_vae_classifier.py:207 - Decoder final activation: Tanh\n",
      "/home/diego/anaconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "2025-06-04 16:07:34,026 - INFO - train_vae_classifier.py:568 - LR Scheduler ReduceLROnPlateau activado con paciencia 15.\n",
      "2025-06-04 16:07:34,026 - INFO - train_vae_classifier.py:570 - Entrenando VAE para el fold 5...\n",
      "2025-06-04 16:07:38,223 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 10/450, Train Loss: 39041.6352, LR: 1.00e-04, Val Loss: 40324.0440\n",
      "2025-06-04 16:07:42,328 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 20/450, Train Loss: 33858.5473, LR: 1.00e-04, Val Loss: 35675.2917\n",
      "2025-06-04 16:07:46,519 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 30/450, Train Loss: 31184.7457, LR: 1.00e-04, Val Loss: 33234.3479\n",
      "2025-06-04 16:07:50,666 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 40/450, Train Loss: 29380.9553, LR: 1.00e-04, Val Loss: 31973.8971\n",
      "2025-06-04 16:07:54,821 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 50/450, Train Loss: 28118.2431, LR: 1.00e-04, Val Loss: 31230.0043\n",
      "2025-06-04 16:07:58,954 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 60/450, Train Loss: 27069.8830, LR: 1.00e-04, Val Loss: 30464.5542\n",
      "2025-06-04 16:08:03,091 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 70/450, Train Loss: 26184.8201, LR: 1.00e-04, Val Loss: 30202.8949\n",
      "2025-06-04 16:08:07,273 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 80/450, Train Loss: 25455.4406, LR: 1.00e-04, Val Loss: 29713.2285\n",
      "2025-06-04 16:08:11,443 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 90/450, Train Loss: 24808.7912, LR: 1.00e-04, Val Loss: 29377.9684\n",
      "2025-06-04 16:08:15,561 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 100/450, Train Loss: 24303.9108, LR: 1.00e-04, Val Loss: 29272.4889\n",
      "2025-06-04 16:08:19,757 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 110/450, Train Loss: 23810.3258, LR: 1.00e-04, Val Loss: 28894.5855\n",
      "2025-06-04 16:08:23,851 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 120/450, Train Loss: 23401.9765, LR: 1.00e-04, Val Loss: 28761.7174\n",
      "2025-06-04 16:08:27,969 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 130/450, Train Loss: 23003.2834, LR: 1.00e-04, Val Loss: 28689.6133\n",
      "2025-06-04 16:08:32,072 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 140/450, Train Loss: 22656.1217, LR: 1.00e-04, Val Loss: 28627.6358\n",
      "2025-06-04 16:08:36,172 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 150/450, Train Loss: 22319.8982, LR: 1.00e-04, Val Loss: 28643.0438\n",
      "2025-06-04 16:08:40,361 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 160/450, Train Loss: 22066.2480, LR: 1.00e-04, Val Loss: 28496.4404\n",
      "2025-06-04 16:08:44,515 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 170/450, Train Loss: 21809.5527, LR: 1.00e-04, Val Loss: 28690.7454\n",
      "2025-06-04 16:08:48,631 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 180/450, Train Loss: 21534.9628, LR: 1.00e-04, Val Loss: 28468.0508\n",
      "2025-06-04 16:08:52,785 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 190/450, Train Loss: 21206.1507, LR: 1.00e-05, Val Loss: 28239.0336\n",
      "2025-06-04 16:08:56,936 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 200/450, Train Loss: 21058.1003, LR: 1.00e-05, Val Loss: 28259.6121\n",
      "2025-06-04 16:09:01,094 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 210/450, Train Loss: 20997.6450, LR: 1.00e-05, Val Loss: 28234.5839\n",
      "2025-06-04 16:09:05,222 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 220/450, Train Loss: 20938.2754, LR: 1.00e-05, Val Loss: 28268.0647\n",
      "2025-06-04 16:09:09,327 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 230/450, Train Loss: 20913.0927, LR: 1.00e-06, Val Loss: 28228.8298\n",
      "2025-06-04 16:09:13,476 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 240/450, Train Loss: 20929.8163, LR: 1.00e-07, Val Loss: 28245.1978\n",
      "2025-06-04 16:09:17,718 - INFO - train_vae_classifier.py:618 - Fold 5, VAE Epoch 250/450, Train Loss: 20943.7582, LR: 1.00e-07, Val Loss: 28245.6395\n",
      "2025-06-04 16:09:19,390 - INFO - train_vae_classifier.py:614 - Fold 5: Early stopping VAE en epoch 254. Mejor val_loss: 28207.6224\n",
      "2025-06-04 16:09:19,390 - INFO - train_vae_classifier.py:621 - Fold 5: Cargando mejor modelo VAE con val_loss: 28207.6224\n",
      "2025-06-04 16:09:19,937 - INFO - train_vae_classifier.py:628 - Modelo VAE del fold 5 guardado en: resultados/corrida_zscore_tanh_v1.3/vae_fold_5_ld512_beta1.0_ch3.pt\n",
      "2025-06-04 16:09:19,943 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:09:19,967 - INFO - train_vae_classifier.py:402 - Aplicando parámetros de normalización precalculados a subconjunto de datos (3 canales).\n",
      "2025-06-04 16:09:19,987 - INFO - train_vae_classifier.py:663 - Entrenando clasificador SVM para el fold 5...\n",
      "2025-06-04 16:09:20,868 - INFO - train_vae_classifier.py:665 - Mejores hiperparámetros SVM para fold 5: {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}\n",
      "2025-06-04 16:09:20,872 - INFO - train_vae_classifier.py:677 - Fold 5 - Resultados Clasificador:\n",
      "2025-06-04 16:09:20,872 - INFO - train_vae_classifier.py:678 -   AUC: 0.7957, PR-AUC: 0.8433, Acc: 0.7500\n",
      "2025-06-04 16:09:20,872 - INFO - train_vae_classifier.py:679 -   Sens (AD): 0.7895, Spec (CN): 0.7059, F1 (AD): 0.7692\n",
      "2025-06-04 16:09:20,873 - INFO - train_vae_classifier.py:686 -   Fold 5 Train (Clf) IDs Hash: 6891443eec6612c557e4d769a0336b04\n",
      "2025-06-04 16:09:20,873 - INFO - train_vae_classifier.py:687 -   Fold 5 Test (Clf) IDs Hash: d978e3b3ff860bbf98ed778172044446\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:702 - \n",
      "--- Resumen de Rendimiento (Promedio sobre Folds Externos) ---\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:706 - Auc         : 0.7767 +/- 0.0585\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:706 - Pr_auc      : 0.8058 +/- 0.0495\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:706 - Accuracy    : 0.7176 +/- 0.0642\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:706 - Sensitivity : 0.7368 +/- 0.1053\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:706 - Specificity : 0.6967 +/- 0.1597\n",
      "2025-06-04 16:09:20,980 - INFO - train_vae_classifier.py:706 - F1_score    : 0.7286 +/- 0.0611\n",
      "2025-06-04 16:09:20,982 - INFO - train_vae_classifier.py:720 - Resultados de clasificación guardados en: resultados/corrida_zscore_tanh_v1.3/clf_results_vae_svm_zscore_offdiag_ld512_beta1.0_ch3sel_intFC0_drop0.2_es50.csv\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:792 - Pipeline completado.\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:793 - --- Consideraciones sobre Normalización y Activación Final del VAE ---\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:794 - Normalización:\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:795 -  - 'minmax_offdiag': Escala los valores fuera de la diagonal de cada canal a [0,1] (usando params de train o fijos).\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:796 -    Ideal con activación final 'sigmoid' en el VAE.\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:797 -  - 'zscore_offdiag': Estandariza los valores fuera de la diagonal (media 0, std 1, usando params de train).\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:798 -    Puede ser mejor con activación final 'tanh' (para rango ~[-1,1]) o 'linear' (sin restricción de rango).\n",
      "2025-06-04 16:09:20,984 - INFO - train_vae_classifier.py:799 - Activación Final del Decoder VAE:\n",
      "2025-06-04 16:09:20,985 - INFO - train_vae_classifier.py:800 -  - 'sigmoid': Comprime la salida a [0,1]. Adecuada si los datos normalizados están en este rango.\n",
      "2025-06-04 16:09:20,985 - INFO - train_vae_classifier.py:801 -  - 'tanh': Comprime la salida a [-1,1]. Adecuada para datos normalizados a este rango (ej. Z-scores reescalados) o Z-scores.\n",
      "2025-06-04 16:09:20,985 - INFO - train_vae_classifier.py:802 -  - 'linear' (None): Sin activación final. La salida puede tomar cualquier valor. Útil si no se desea restringir el rango o si los datos normalizados (ej. Z-scores) no tienen un rango acotado claro.\n",
      "2025-06-04 16:09:20,985 - INFO - train_vae_classifier.py:803 - La elección depende de la distribución de tus datos después de la normalización y de los objetivos de la reconstrucción.\n",
      "2025-06-04 16:09:20,985 - INFO - train_vae_classifier.py:804 - Si usas los parámetros MinMax fijos para ciertos canales, estos se mapearán a [0,1], lo que es compatible con 'sigmoid'.\n"
     ]
    }
   ],
   "source": [
    "!python train_vae_classifier.py \\\n",
    "    --global_tensor_path /home/diego/Escritorio/AAL3/AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned/GLOBAL_TENSOR_from_AAL3_dynamicROIs_fmri_tensor_NeuroEnhanced_v6.5.17_AAL3_131ROIs_OMST_GCE_Signed_GrangerLag1_ChNorm_ROIreorderedYeo17_ParallelTuned.npz \\\n",
    "    --metadata_path      /home/diego/Escritorio/AAL3/SubjectsData_Schaefer2018_400ROIs.csv \\\n",
    "    --output_dir         resultados/corrida_zscore_tanh_v1.3 \\\n",
    "    --channels_to_use    1 2 3 \\\n",
    "    --latent_dim         512 \\\n",
    "    --beta_vae           1.0 \\\n",
    "    --epochs_vae         450 \\\n",
    "    --batch_size         32 \\\n",
    "    --vae_val_split_ratio 0.15 \\\n",
    "    --early_stopping_patience_vae 50 \\\n",
    "    --lr_scheduler_patience_vae   15 \\\n",
    "    --norm_mode          zscore_offdiag \\\n",
    "    --vae_final_activation tanh \\\n",
    "    --class_weight_svm \\\n",
    "    --seed               42\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
